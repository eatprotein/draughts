{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNKtI8SdPp3mHapRQ6G2JAw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eatprotein/draughts/blob/main/ML_transformer_drybean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1:Download the dataset"
      ],
      "metadata": {
        "id": "1tV1tbNzG3Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up drives for resources.  Change the path as necessary\n",
        "\n",
        "from google.colab import drive\n",
        "#mount google drive\n",
        "drive.mount('/content/drive/')\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/NLE Notebooks/resources/')\n"
      ],
      "metadata": {
        "id": "vrXMRIVAK0ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brtdIyb6fx7O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Download and save the dataset\n",
        "dataset_url = \"/content/Dry_Bean_Dataset.xlsx\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Preprocess the data\n"
      ],
      "metadata": {
        "id": "-FNtCOqVHQUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(dataset_url)\n",
        "\n",
        "\n",
        "for col in df.columns:\n",
        "  if col != 'Class':\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "MZmQ_sNOHD7J",
        "outputId": "aed5e165-1101-4ebd-c25a-19a33b967f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "0  28395.0    610.291       208.178117       173.888747      1.197191   \n",
              "1  28734.0    638.018       200.524796       182.734419      1.097356   \n",
              "2  29380.0    624.110       212.826130       175.931143      1.209713   \n",
              "3  30008.0    645.884       210.557999       182.516516      1.153638   \n",
              "4  30140.0    620.134       201.847882       190.279279      1.060798   \n",
              "\n",
              "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "0      0.549812     28715.0     190.141097  0.763923  0.988856   0.958027   \n",
              "1      0.411785     29172.0     191.272750  0.783968  0.984986   0.887034   \n",
              "2      0.562727     29690.0     193.410904  0.778113  0.989559   0.947849   \n",
              "3      0.498616     30724.0     195.467062  0.782681  0.976696   0.903936   \n",
              "4      0.333680     30417.0     195.896503  0.773098  0.990893   0.984877   \n",
              "\n",
              "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
              "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
              "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
              "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
              "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
              "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd4bbb24-ae0f-4dc6-8d00-62daa7d3a6b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28395.0</td>\n",
              "      <td>610.291</td>\n",
              "      <td>208.178117</td>\n",
              "      <td>173.888747</td>\n",
              "      <td>1.197191</td>\n",
              "      <td>0.549812</td>\n",
              "      <td>28715.0</td>\n",
              "      <td>190.141097</td>\n",
              "      <td>0.763923</td>\n",
              "      <td>0.988856</td>\n",
              "      <td>0.958027</td>\n",
              "      <td>0.913358</td>\n",
              "      <td>0.007332</td>\n",
              "      <td>0.003147</td>\n",
              "      <td>0.834222</td>\n",
              "      <td>0.998724</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28734.0</td>\n",
              "      <td>638.018</td>\n",
              "      <td>200.524796</td>\n",
              "      <td>182.734419</td>\n",
              "      <td>1.097356</td>\n",
              "      <td>0.411785</td>\n",
              "      <td>29172.0</td>\n",
              "      <td>191.272750</td>\n",
              "      <td>0.783968</td>\n",
              "      <td>0.984986</td>\n",
              "      <td>0.887034</td>\n",
              "      <td>0.953861</td>\n",
              "      <td>0.006979</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.909851</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29380.0</td>\n",
              "      <td>624.110</td>\n",
              "      <td>212.826130</td>\n",
              "      <td>175.931143</td>\n",
              "      <td>1.209713</td>\n",
              "      <td>0.562727</td>\n",
              "      <td>29690.0</td>\n",
              "      <td>193.410904</td>\n",
              "      <td>0.778113</td>\n",
              "      <td>0.989559</td>\n",
              "      <td>0.947849</td>\n",
              "      <td>0.908774</td>\n",
              "      <td>0.007244</td>\n",
              "      <td>0.003048</td>\n",
              "      <td>0.825871</td>\n",
              "      <td>0.999066</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30008.0</td>\n",
              "      <td>645.884</td>\n",
              "      <td>210.557999</td>\n",
              "      <td>182.516516</td>\n",
              "      <td>1.153638</td>\n",
              "      <td>0.498616</td>\n",
              "      <td>30724.0</td>\n",
              "      <td>195.467062</td>\n",
              "      <td>0.782681</td>\n",
              "      <td>0.976696</td>\n",
              "      <td>0.903936</td>\n",
              "      <td>0.928329</td>\n",
              "      <td>0.007017</td>\n",
              "      <td>0.003215</td>\n",
              "      <td>0.861794</td>\n",
              "      <td>0.994199</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30140.0</td>\n",
              "      <td>620.134</td>\n",
              "      <td>201.847882</td>\n",
              "      <td>190.279279</td>\n",
              "      <td>1.060798</td>\n",
              "      <td>0.333680</td>\n",
              "      <td>30417.0</td>\n",
              "      <td>195.896503</td>\n",
              "      <td>0.773098</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.984877</td>\n",
              "      <td>0.970516</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>0.003665</td>\n",
              "      <td>0.941900</td>\n",
              "      <td>0.999166</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd4bbb24-ae0f-4dc6-8d00-62daa7d3a6b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd4bbb24-ae0f-4dc6-8d00-62daa7d3a6b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd4bbb24-ae0f-4dc6-8d00-62daa7d3a6b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create the model\n",
        "\n",
        "# If a GPU is available, try comparing performance between CPU and GPU\n",
        "request_GPU = True\n",
        "\n",
        "# Use GPU if supported and requested, CPU otherwise \n",
        "if torch.cuda.is_available() and request_GPU:\n",
        "    device = torch.device('cuda')\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('Using the CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwstojD8-9Fi",
        "outputId": "e22fbc54-83d0-41cc-c366-9c68cb54b98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder and transform the 'Class' column\n",
        "df['Class'] = le.fit_transform(df['Class'])\n"
      ],
      "metadata": {
        "id": "NiJMh6_EsesV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Split the dataset "
      ],
      "metadata": {
        "id": "FAr3Q7aTBnJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader objects for batching and shuffling the data during training\n",
        "batch_size = 32\n",
        "\n",
        "class BeanDataset(TensorDataset):\n",
        "    def __init__(self, features, targets):\n",
        "      self.features = np.array(features, dtype=np.float32)\n",
        "      self.targets = np.array(targets, dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # Convert the data to PyTorch tensors\n",
        "      return torch.tensor(self.features[idx]), torch.tensor(self.targets[idx])\n"
      ],
      "metadata": {
        "id": "vvE7Ggm1j1Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train, validation, and test sets\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)\n",
        "\n",
        "print('Training set:', X_train.shape, y_train.shape)\n",
        "print('Validation set:', X_val.shape, y_val.shape)\n",
        "print('Test set:', X_test.shape, y_test.shape)\n",
        "\n",
        "# Create DataLoader objects for batching and shuffling the data during training\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = BeanDataset(X_train, y_train)\n",
        "val_dataset = BeanDataset(X_val, y_val)    # New validation dataset\n",
        "test_dataset = BeanDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)    # New validation loader\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDN4XQkyhqWw",
        "outputId": "15e531c3-f3a6-4e97-9d5e-f17769f2e1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (8166, 16) (8166,)\n",
            "Validation set: (2722, 16) (2722,)\n",
            "Test set: (2723, 16) (2723,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Build the Transformer model\n"
      ],
      "metadata": {
        "id": "rsvj0_ijAPwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim, num_layers, num_heads, dropout):\n",
        "    # Define Transformer model architecture using nn.TransformerEncoder\n",
        "    super(TransformerModel, self).__init__()\n",
        "    self.embedding = nn.Linear(input_dim, hidden_dim)\n",
        "    encoder_layer = TransformerEncoderLayer(hidden_dim, num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n",
        "    self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Implement the forward pass logic of Transformer model\n",
        "    x = self.embedding(x)\n",
        "    x = x.unsqueeze(1)  # Add an additional dimension for sequence length\n",
        "    x = self.transformer_encoder(x)\n",
        "    x = x.mean(dim=1)  # Average pooling over the sequence length\n",
        "    output = self.fc(x)\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "lwMPhSVlhDt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "hidden_dim = 64\n",
        "num_layers = 2\n",
        "num_heads = 4\n",
        "dropout = 0.1"
      ],
      "metadata": {
        "id": "HVm963Yfg8cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Train the model"
      ],
      "metadata": {
        "id": "z5TlSfYkAHjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "input_dim = X_train.shape[1]  # Number of input features\n",
        "output_dim = len(df['Class'].unique())  # Number of output classes\n",
        "hidden_dim = 64\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model\n",
        "model = TransformerModel(input_dim, output_dim, hidden_dim, num_layers, num_heads, dropout)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "jbyb5OMhgwYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "  \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "        \n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels.long())\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
        "        \n",
        "        # Early stopping\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "        else:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    # Plotting the losses\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5Z3gqSSxN0wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "\n",
        "#     model.train()\n",
        "#     train_loss = 0.0\n",
        "#     for inputs, labels in train_loader:\n",
        "#       optimizer.zero_grad()\n",
        "#       outputs = model(inputs)\n",
        "#       loss = criterion(outputs, labels.long())\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "#       train_loss += loss.item() * inputs.size(0)\n",
        "#     model.eval()\n",
        "#     val_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     with torch.no_grad():\n",
        "#       for inputs, labels in val_loader:\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, labels.long())\n",
        "#         val_loss += loss.item() * inputs.size(0)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "#     avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "#     avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "#     val_accuracy = correct / total\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
        "#   return model\n"
      ],
      "metadata": {
        "id": "JHjoN7CK7AOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Evaluate the model on the test set\n"
      ],
      "metadata": {
        "id": "r5zh7xNPHiqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, criterion, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels.long())\n",
        "      test_loss += loss.item() * inputs.size(0)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  avg_test_loss = test_loss / len(test_loader.dataset)\n",
        "  test_accuracy = correct / total\n",
        "  print(f\"Test Loss: {avg_test_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\n",
        "  return test_accuracy\n"
      ],
      "metadata": {
        "id": "iT9M5Bft7HCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Iterate and fine-tune if necessary\n",
        "\n"
      ],
      "metadata": {
        "id": "344rYqc-HRwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the evaluation results, adjust hyperparameters, change model architecture, \n",
        "# or try different preprocessing techniques."
      ],
      "metadata": {
        "id": "kSppw7vDGqzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a set of hyperparameters to try\n",
        "hidden_dims = [64, 128, 256]\n",
        "num_layers_list = [2, 3, 4]\n",
        "num_heads_list = [4, 8, 16]\n",
        "dropouts = [0.1, 0.2, 0.3]\n",
        "\n",
        "# Keep track of the best model and its performance\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Iterate over all combinations of hyperparameters\n",
        "for hidden_dim in hidden_dims:\n",
        "  for num_layers in num_layers_list:\n",
        "    for num_heads in num_heads_list:\n",
        "      for dropout in dropouts:\n",
        "        # Create and train a new model with this set of hyperparameters\n",
        "        model = TransformerModel(input_dim, output_dim, hidden_dim, num_layers, num_heads, dropout)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        model = train_model(model, criterion, optimizer, train_loader)  # Training function\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        accuracy = evaluate_model(model, criterion, test_loader)  # Evaluation function\n",
        "\n",
        "        # If this model is better than the current best, update the best model\n",
        "        if accuracy > best_accuracy:\n",
        "          best_model = model\n",
        "          best_accuracy = accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS6u8OKrnNod",
        "outputId": "c84e42d2-9dfd-43f4-9c04-7975faa4fe99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.3763 | Val Loss: 0.2195 | Val Acc: 0.9206\n",
            "Epoch 2/10 | Train Loss: 0.2379 | Val Loss: 0.1956 | Val Acc: 0.9298\n",
            "Epoch 3/10 | Train Loss: 0.2257 | Val Loss: 0.1956 | Val Acc: 0.9317\n",
            "Epoch 4/10 | Train Loss: 0.2227 | Val Loss: 0.2046 | Val Acc: 0.9306\n",
            "Epoch 5/10 | Train Loss: 0.2134 | Val Loss: 0.1885 | Val Acc: 0.9331\n",
            "Epoch 6/10 | Train Loss: 0.2146 | Val Loss: 0.1792 | Val Acc: 0.9357\n",
            "Epoch 7/10 | Train Loss: 0.2072 | Val Loss: 0.1971 | Val Acc: 0.9339\n",
            "Epoch 8/10 | Train Loss: 0.2106 | Val Loss: 0.1816 | Val Acc: 0.9372\n",
            "Epoch 9/10 | Train Loss: 0.2018 | Val Loss: 0.1865 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2033 | Val Loss: 0.2010 | Val Acc: 0.9284\n",
            "Test Loss: 0.2009 | Test Acc: 0.9284\n",
            "Epoch 1/10 | Train Loss: 0.4067 | Val Loss: 0.2013 | Val Acc: 0.9317\n",
            "Epoch 2/10 | Train Loss: 0.2469 | Val Loss: 0.1933 | Val Acc: 0.9342\n",
            "Epoch 3/10 | Train Loss: 0.2311 | Val Loss: 0.1991 | Val Acc: 0.9298\n",
            "Epoch 4/10 | Train Loss: 0.2260 | Val Loss: 0.1891 | Val Acc: 0.9331\n",
            "Epoch 5/10 | Train Loss: 0.2188 | Val Loss: 0.2121 | Val Acc: 0.9177\n",
            "Epoch 6/10 | Train Loss: 0.2184 | Val Loss: 0.2034 | Val Acc: 0.9240\n",
            "Epoch 7/10 | Train Loss: 0.2107 | Val Loss: 0.1894 | Val Acc: 0.9317\n",
            "Epoch 8/10 | Train Loss: 0.2129 | Val Loss: 0.1817 | Val Acc: 0.9372\n",
            "Epoch 9/10 | Train Loss: 0.2090 | Val Loss: 0.2056 | Val Acc: 0.9188\n",
            "Epoch 10/10 | Train Loss: 0.2091 | Val Loss: 0.1925 | Val Acc: 0.9306\n",
            "Test Loss: 0.1924 | Test Acc: 0.9306\n",
            "Epoch 1/10 | Train Loss: 0.4380 | Val Loss: 0.2225 | Val Acc: 0.9225\n",
            "Epoch 2/10 | Train Loss: 0.2576 | Val Loss: 0.1956 | Val Acc: 0.9291\n",
            "Epoch 3/10 | Train Loss: 0.2401 | Val Loss: 0.1935 | Val Acc: 0.9313\n",
            "Epoch 4/10 | Train Loss: 0.2330 | Val Loss: 0.1861 | Val Acc: 0.9324\n",
            "Epoch 5/10 | Train Loss: 0.2269 | Val Loss: 0.1948 | Val Acc: 0.9284\n",
            "Epoch 6/10 | Train Loss: 0.2199 | Val Loss: 0.1844 | Val Acc: 0.9324\n",
            "Epoch 7/10 | Train Loss: 0.2168 | Val Loss: 0.1929 | Val Acc: 0.9317\n",
            "Epoch 8/10 | Train Loss: 0.2157 | Val Loss: 0.1764 | Val Acc: 0.9364\n",
            "Epoch 9/10 | Train Loss: 0.2147 | Val Loss: 0.1886 | Val Acc: 0.9339\n",
            "Epoch 10/10 | Train Loss: 0.2088 | Val Loss: 0.1801 | Val Acc: 0.9346\n",
            "Test Loss: 0.1801 | Test Acc: 0.9346\n",
            "Epoch 1/10 | Train Loss: 0.4220 | Val Loss: 0.2050 | Val Acc: 0.9280\n",
            "Epoch 2/10 | Train Loss: 0.2537 | Val Loss: 0.2223 | Val Acc: 0.9206\n",
            "Epoch 3/10 | Train Loss: 0.2325 | Val Loss: 0.1935 | Val Acc: 0.9346\n",
            "Epoch 4/10 | Train Loss: 0.2202 | Val Loss: 0.1953 | Val Acc: 0.9306\n",
            "Epoch 5/10 | Train Loss: 0.2128 | Val Loss: 0.1970 | Val Acc: 0.9287\n",
            "Epoch 6/10 | Train Loss: 0.2158 | Val Loss: 0.1930 | Val Acc: 0.9353\n",
            "Epoch 7/10 | Train Loss: 0.2078 | Val Loss: 0.1885 | Val Acc: 0.9335\n",
            "Epoch 8/10 | Train Loss: 0.2105 | Val Loss: 0.1836 | Val Acc: 0.9350\n",
            "Epoch 9/10 | Train Loss: 0.2043 | Val Loss: 0.1841 | Val Acc: 0.9328\n",
            "Epoch 10/10 | Train Loss: 0.2034 | Val Loss: 0.1786 | Val Acc: 0.9361\n",
            "Test Loss: 0.1785 | Test Acc: 0.9361\n",
            "Epoch 1/10 | Train Loss: 0.3869 | Val Loss: 0.2151 | Val Acc: 0.9254\n",
            "Epoch 2/10 | Train Loss: 0.2436 | Val Loss: 0.2015 | Val Acc: 0.9287\n",
            "Epoch 3/10 | Train Loss: 0.2363 | Val Loss: 0.1902 | Val Acc: 0.9339\n",
            "Epoch 4/10 | Train Loss: 0.2200 | Val Loss: 0.1929 | Val Acc: 0.9284\n",
            "Epoch 5/10 | Train Loss: 0.2176 | Val Loss: 0.1850 | Val Acc: 0.9328\n",
            "Epoch 6/10 | Train Loss: 0.2140 | Val Loss: 0.1873 | Val Acc: 0.9324\n",
            "Epoch 7/10 | Train Loss: 0.2151 | Val Loss: 0.1862 | Val Acc: 0.9309\n",
            "Epoch 8/10 | Train Loss: 0.2085 | Val Loss: 0.1805 | Val Acc: 0.9342\n",
            "Epoch 9/10 | Train Loss: 0.2079 | Val Loss: 0.1792 | Val Acc: 0.9353\n",
            "Epoch 10/10 | Train Loss: 0.2051 | Val Loss: 0.1955 | Val Acc: 0.9328\n",
            "Test Loss: 0.1954 | Test Acc: 0.9328\n",
            "Epoch 1/10 | Train Loss: 0.4528 | Val Loss: 0.2143 | Val Acc: 0.9240\n",
            "Epoch 2/10 | Train Loss: 0.2565 | Val Loss: 0.1866 | Val Acc: 0.9306\n",
            "Epoch 3/10 | Train Loss: 0.2395 | Val Loss: 0.2063 | Val Acc: 0.9217\n",
            "Epoch 4/10 | Train Loss: 0.2334 | Val Loss: 0.1950 | Val Acc: 0.9306\n",
            "Epoch 5/10 | Train Loss: 0.2286 | Val Loss: 0.1920 | Val Acc: 0.9306\n",
            "Epoch 6/10 | Train Loss: 0.2197 | Val Loss: 0.1871 | Val Acc: 0.9342\n",
            "Epoch 7/10 | Train Loss: 0.2188 | Val Loss: 0.1871 | Val Acc: 0.9342\n",
            "Epoch 8/10 | Train Loss: 0.2130 | Val Loss: 0.1808 | Val Acc: 0.9331\n",
            "Epoch 9/10 | Train Loss: 0.2146 | Val Loss: 0.1797 | Val Acc: 0.9372\n",
            "Epoch 10/10 | Train Loss: 0.2084 | Val Loss: 0.1815 | Val Acc: 0.9346\n",
            "Test Loss: 0.1815 | Test Acc: 0.9346\n",
            "Epoch 1/10 | Train Loss: 0.3937 | Val Loss: 0.2019 | Val Acc: 0.9280\n",
            "Epoch 2/10 | Train Loss: 0.2421 | Val Loss: 0.1875 | Val Acc: 0.9324\n",
            "Epoch 3/10 | Train Loss: 0.2315 | Val Loss: 0.2230 | Val Acc: 0.9177\n",
            "Epoch 4/10 | Train Loss: 0.2234 | Val Loss: 0.1888 | Val Acc: 0.9357\n",
            "Epoch 5/10 | Train Loss: 0.2163 | Val Loss: 0.1970 | Val Acc: 0.9313\n",
            "Epoch 6/10 | Train Loss: 0.2120 | Val Loss: 0.1934 | Val Acc: 0.9324\n",
            "Epoch 7/10 | Train Loss: 0.2125 | Val Loss: 0.2113 | Val Acc: 0.9206\n",
            "Epoch 8/10 | Train Loss: 0.2061 | Val Loss: 0.2033 | Val Acc: 0.9280\n",
            "Epoch 9/10 | Train Loss: 0.2026 | Val Loss: 0.1867 | Val Acc: 0.9295\n",
            "Epoch 10/10 | Train Loss: 0.1981 | Val Loss: 0.1785 | Val Acc: 0.9375\n",
            "Test Loss: 0.1784 | Test Acc: 0.9375\n",
            "Epoch 1/10 | Train Loss: 0.4143 | Val Loss: 0.2241 | Val Acc: 0.9232\n",
            "Epoch 2/10 | Train Loss: 0.2475 | Val Loss: 0.2152 | Val Acc: 0.9240\n",
            "Epoch 3/10 | Train Loss: 0.2367 | Val Loss: 0.2146 | Val Acc: 0.9206\n",
            "Epoch 4/10 | Train Loss: 0.2219 | Val Loss: 0.1978 | Val Acc: 0.9313\n",
            "Epoch 5/10 | Train Loss: 0.2204 | Val Loss: 0.1948 | Val Acc: 0.9324\n",
            "Epoch 6/10 | Train Loss: 0.2171 | Val Loss: 0.1818 | Val Acc: 0.9353\n",
            "Epoch 7/10 | Train Loss: 0.2148 | Val Loss: 0.1993 | Val Acc: 0.9298\n",
            "Epoch 8/10 | Train Loss: 0.2108 | Val Loss: 0.1999 | Val Acc: 0.9295\n",
            "Epoch 9/10 | Train Loss: 0.2104 | Val Loss: 0.1921 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2064 | Val Loss: 0.1869 | Val Acc: 0.9342\n",
            "Test Loss: 0.1868 | Test Acc: 0.9342\n",
            "Epoch 1/10 | Train Loss: 0.4309 | Val Loss: 0.2162 | Val Acc: 0.9240\n",
            "Epoch 2/10 | Train Loss: 0.2561 | Val Loss: 0.2069 | Val Acc: 0.9214\n",
            "Epoch 3/10 | Train Loss: 0.2402 | Val Loss: 0.1972 | Val Acc: 0.9265\n",
            "Epoch 4/10 | Train Loss: 0.2345 | Val Loss: 0.1987 | Val Acc: 0.9295\n",
            "Epoch 5/10 | Train Loss: 0.2241 | Val Loss: 0.1924 | Val Acc: 0.9342\n",
            "Epoch 6/10 | Train Loss: 0.2200 | Val Loss: 0.1833 | Val Acc: 0.9313\n",
            "Epoch 7/10 | Train Loss: 0.2164 | Val Loss: 0.1852 | Val Acc: 0.9350\n",
            "Epoch 8/10 | Train Loss: 0.2139 | Val Loss: 0.1801 | Val Acc: 0.9350\n",
            "Epoch 9/10 | Train Loss: 0.2113 | Val Loss: 0.1820 | Val Acc: 0.9339\n",
            "Epoch 10/10 | Train Loss: 0.2089 | Val Loss: 0.1872 | Val Acc: 0.9346\n",
            "Test Loss: 0.1871 | Test Acc: 0.9346\n",
            "Epoch 1/10 | Train Loss: 0.3878 | Val Loss: 0.2396 | Val Acc: 0.9144\n",
            "Epoch 2/10 | Train Loss: 0.2491 | Val Loss: 0.2624 | Val Acc: 0.9067\n",
            "Epoch 3/10 | Train Loss: 0.2310 | Val Loss: 0.2079 | Val Acc: 0.9269\n",
            "Epoch 4/10 | Train Loss: 0.2293 | Val Loss: 0.1908 | Val Acc: 0.9309\n",
            "Epoch 5/10 | Train Loss: 0.2171 | Val Loss: 0.2008 | Val Acc: 0.9287\n",
            "Epoch 6/10 | Train Loss: 0.2156 | Val Loss: 0.1986 | Val Acc: 0.9287\n",
            "Epoch 7/10 | Train Loss: 0.2115 | Val Loss: 0.1828 | Val Acc: 0.9350\n",
            "Epoch 8/10 | Train Loss: 0.2076 | Val Loss: 0.2023 | Val Acc: 0.9269\n",
            "Epoch 9/10 | Train Loss: 0.2072 | Val Loss: 0.1963 | Val Acc: 0.9306\n",
            "Epoch 10/10 | Train Loss: 0.2040 | Val Loss: 0.1958 | Val Acc: 0.9324\n",
            "Test Loss: 0.1957 | Test Acc: 0.9324\n",
            "Epoch 1/10 | Train Loss: 0.4400 | Val Loss: 0.2126 | Val Acc: 0.9251\n",
            "Epoch 2/10 | Train Loss: 0.2629 | Val Loss: 0.1962 | Val Acc: 0.9324\n",
            "Epoch 3/10 | Train Loss: 0.2422 | Val Loss: 0.2342 | Val Acc: 0.9151\n",
            "Epoch 4/10 | Train Loss: 0.2316 | Val Loss: 0.2195 | Val Acc: 0.9221\n",
            "Epoch 5/10 | Train Loss: 0.2319 | Val Loss: 0.1850 | Val Acc: 0.9353\n",
            "Epoch 6/10 | Train Loss: 0.2213 | Val Loss: 0.1970 | Val Acc: 0.9269\n",
            "Epoch 7/10 | Train Loss: 0.2219 | Val Loss: 0.1810 | Val Acc: 0.9317\n",
            "Epoch 8/10 | Train Loss: 0.2149 | Val Loss: 0.1928 | Val Acc: 0.9339\n",
            "Epoch 9/10 | Train Loss: 0.2132 | Val Loss: 0.1833 | Val Acc: 0.9339\n",
            "Epoch 10/10 | Train Loss: 0.2084 | Val Loss: 0.1996 | Val Acc: 0.9280\n",
            "Test Loss: 0.1996 | Test Acc: 0.9280\n",
            "Epoch 1/10 | Train Loss: 0.4673 | Val Loss: 0.2251 | Val Acc: 0.9225\n",
            "Epoch 2/10 | Train Loss: 0.2707 | Val Loss: 0.1963 | Val Acc: 0.9291\n",
            "Epoch 3/10 | Train Loss: 0.2490 | Val Loss: 0.2017 | Val Acc: 0.9240\n",
            "Epoch 4/10 | Train Loss: 0.2363 | Val Loss: 0.1856 | Val Acc: 0.9306\n",
            "Epoch 5/10 | Train Loss: 0.2331 | Val Loss: 0.1811 | Val Acc: 0.9342\n",
            "Epoch 6/10 | Train Loss: 0.2224 | Val Loss: 0.1920 | Val Acc: 0.9298\n",
            "Epoch 7/10 | Train Loss: 0.2219 | Val Loss: 0.1829 | Val Acc: 0.9350\n",
            "Epoch 8/10 | Train Loss: 0.2142 | Val Loss: 0.1851 | Val Acc: 0.9346\n",
            "Epoch 9/10 | Train Loss: 0.2165 | Val Loss: 0.1857 | Val Acc: 0.9317\n",
            "Epoch 10/10 | Train Loss: 0.2119 | Val Loss: 0.1962 | Val Acc: 0.9295\n",
            "Test Loss: 0.1961 | Test Acc: 0.9295\n",
            "Epoch 1/10 | Train Loss: 0.3747 | Val Loss: 0.2258 | Val Acc: 0.9195\n",
            "Epoch 2/10 | Train Loss: 0.2492 | Val Loss: 0.1939 | Val Acc: 0.9309\n",
            "Epoch 3/10 | Train Loss: 0.2375 | Val Loss: 0.2036 | Val Acc: 0.9225\n",
            "Epoch 4/10 | Train Loss: 0.2273 | Val Loss: 0.1859 | Val Acc: 0.9346\n",
            "Epoch 5/10 | Train Loss: 0.2132 | Val Loss: 0.1862 | Val Acc: 0.9361\n",
            "Epoch 6/10 | Train Loss: 0.2148 | Val Loss: 0.1940 | Val Acc: 0.9298\n",
            "Epoch 7/10 | Train Loss: 0.2137 | Val Loss: 0.1816 | Val Acc: 0.9350\n",
            "Epoch 8/10 | Train Loss: 0.2099 | Val Loss: 0.2030 | Val Acc: 0.9273\n",
            "Epoch 9/10 | Train Loss: 0.2110 | Val Loss: 0.1974 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2066 | Val Loss: 0.2151 | Val Acc: 0.9214\n",
            "Test Loss: 0.2150 | Test Acc: 0.9214\n",
            "Epoch 1/10 | Train Loss: 0.4010 | Val Loss: 0.2502 | Val Acc: 0.9071\n",
            "Epoch 2/10 | Train Loss: 0.2541 | Val Loss: 0.2047 | Val Acc: 0.9306\n",
            "Epoch 3/10 | Train Loss: 0.2391 | Val Loss: 0.1974 | Val Acc: 0.9276\n",
            "Epoch 4/10 | Train Loss: 0.2330 | Val Loss: 0.1985 | Val Acc: 0.9269\n",
            "Epoch 5/10 | Train Loss: 0.2265 | Val Loss: 0.2018 | Val Acc: 0.9229\n",
            "Epoch 6/10 | Train Loss: 0.2204 | Val Loss: 0.1932 | Val Acc: 0.9302\n",
            "Epoch 7/10 | Train Loss: 0.2161 | Val Loss: 0.1806 | Val Acc: 0.9328\n",
            "Epoch 8/10 | Train Loss: 0.2167 | Val Loss: 0.1981 | Val Acc: 0.9265\n",
            "Epoch 9/10 | Train Loss: 0.2135 | Val Loss: 0.1973 | Val Acc: 0.9280\n",
            "Epoch 10/10 | Train Loss: 0.2102 | Val Loss: 0.1825 | Val Acc: 0.9372\n",
            "Test Loss: 0.1824 | Test Acc: 0.9372\n",
            "Epoch 1/10 | Train Loss: 0.4134 | Val Loss: 0.2199 | Val Acc: 0.9247\n",
            "Epoch 2/10 | Train Loss: 0.2639 | Val Loss: 0.1969 | Val Acc: 0.9251\n",
            "Epoch 3/10 | Train Loss: 0.2451 | Val Loss: 0.2055 | Val Acc: 0.9269\n",
            "Epoch 4/10 | Train Loss: 0.2375 | Val Loss: 0.2095 | Val Acc: 0.9276\n",
            "Epoch 5/10 | Train Loss: 0.2316 | Val Loss: 0.1968 | Val Acc: 0.9287\n",
            "Epoch 6/10 | Train Loss: 0.2199 | Val Loss: 0.1879 | Val Acc: 0.9339\n",
            "Epoch 7/10 | Train Loss: 0.2207 | Val Loss: 0.1846 | Val Acc: 0.9331\n",
            "Epoch 8/10 | Train Loss: 0.2154 | Val Loss: 0.1807 | Val Acc: 0.9368\n",
            "Epoch 9/10 | Train Loss: 0.2137 | Val Loss: 0.2005 | Val Acc: 0.9280\n",
            "Epoch 10/10 | Train Loss: 0.2153 | Val Loss: 0.1903 | Val Acc: 0.9302\n",
            "Test Loss: 0.1902 | Test Acc: 0.9302\n",
            "Epoch 1/10 | Train Loss: 0.3747 | Val Loss: 0.2529 | Val Acc: 0.9085\n",
            "Epoch 2/10 | Train Loss: 0.2443 | Val Loss: 0.2525 | Val Acc: 0.9085\n",
            "Epoch 3/10 | Train Loss: 0.2310 | Val Loss: 0.2083 | Val Acc: 0.9243\n",
            "Epoch 4/10 | Train Loss: 0.2151 | Val Loss: 0.2050 | Val Acc: 0.9247\n",
            "Epoch 5/10 | Train Loss: 0.2182 | Val Loss: 0.2300 | Val Acc: 0.9122\n",
            "Epoch 6/10 | Train Loss: 0.2181 | Val Loss: 0.1916 | Val Acc: 0.9324\n",
            "Epoch 7/10 | Train Loss: 0.2103 | Val Loss: 0.2094 | Val Acc: 0.9229\n",
            "Epoch 8/10 | Train Loss: 0.2038 | Val Loss: 0.1963 | Val Acc: 0.9265\n",
            "Epoch 9/10 | Train Loss: 0.2004 | Val Loss: 0.1949 | Val Acc: 0.9306\n",
            "Epoch 10/10 | Train Loss: 0.2042 | Val Loss: 0.1875 | Val Acc: 0.9357\n",
            "Test Loss: 0.1874 | Test Acc: 0.9357\n",
            "Epoch 1/10 | Train Loss: 0.3882 | Val Loss: 0.2285 | Val Acc: 0.9203\n",
            "Epoch 2/10 | Train Loss: 0.2537 | Val Loss: 0.2221 | Val Acc: 0.9240\n",
            "Epoch 3/10 | Train Loss: 0.2363 | Val Loss: 0.2096 | Val Acc: 0.9287\n",
            "Epoch 4/10 | Train Loss: 0.2269 | Val Loss: 0.1900 | Val Acc: 0.9353\n",
            "Epoch 5/10 | Train Loss: 0.2245 | Val Loss: 0.1842 | Val Acc: 0.9335\n",
            "Epoch 6/10 | Train Loss: 0.2171 | Val Loss: 0.1953 | Val Acc: 0.9324\n",
            "Epoch 7/10 | Train Loss: 0.2189 | Val Loss: 0.1831 | Val Acc: 0.9364\n",
            "Epoch 8/10 | Train Loss: 0.2114 | Val Loss: 0.1817 | Val Acc: 0.9324\n",
            "Epoch 9/10 | Train Loss: 0.2093 | Val Loss: 0.1951 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2051 | Val Loss: 0.1780 | Val Acc: 0.9350\n",
            "Test Loss: 0.1779 | Test Acc: 0.9350\n",
            "Epoch 1/10 | Train Loss: 0.4271 | Val Loss: 0.2204 | Val Acc: 0.9225\n",
            "Epoch 2/10 | Train Loss: 0.2560 | Val Loss: 0.2025 | Val Acc: 0.9284\n",
            "Epoch 3/10 | Train Loss: 0.2487 | Val Loss: 0.2208 | Val Acc: 0.9236\n",
            "Epoch 4/10 | Train Loss: 0.2358 | Val Loss: 0.1936 | Val Acc: 0.9309\n",
            "Epoch 5/10 | Train Loss: 0.2324 | Val Loss: 0.1840 | Val Acc: 0.9353\n",
            "Epoch 6/10 | Train Loss: 0.2256 | Val Loss: 0.1886 | Val Acc: 0.9317\n",
            "Epoch 7/10 | Train Loss: 0.2230 | Val Loss: 0.2221 | Val Acc: 0.9188\n",
            "Epoch 8/10 | Train Loss: 0.2204 | Val Loss: 0.1890 | Val Acc: 0.9342\n",
            "Epoch 9/10 | Train Loss: 0.2153 | Val Loss: 0.2104 | Val Acc: 0.9214\n",
            "Epoch 10/10 | Train Loss: 0.2172 | Val Loss: 0.1818 | Val Acc: 0.9375\n",
            "Test Loss: 0.1817 | Test Acc: 0.9375\n",
            "Epoch 1/10 | Train Loss: 0.3821 | Val Loss: 0.2058 | Val Acc: 0.9313\n",
            "Epoch 2/10 | Train Loss: 0.2483 | Val Loss: 0.1995 | Val Acc: 0.9287\n",
            "Epoch 3/10 | Train Loss: 0.2330 | Val Loss: 0.2268 | Val Acc: 0.9151\n",
            "Epoch 4/10 | Train Loss: 0.2268 | Val Loss: 0.1976 | Val Acc: 0.9302\n",
            "Epoch 5/10 | Train Loss: 0.2155 | Val Loss: 0.2072 | Val Acc: 0.9276\n",
            "Epoch 6/10 | Train Loss: 0.2137 | Val Loss: 0.1885 | Val Acc: 0.9328\n",
            "Epoch 7/10 | Train Loss: 0.2087 | Val Loss: 0.1974 | Val Acc: 0.9287\n",
            "Epoch 8/10 | Train Loss: 0.2064 | Val Loss: 0.1964 | Val Acc: 0.9328\n",
            "Epoch 9/10 | Train Loss: 0.2020 | Val Loss: 0.2039 | Val Acc: 0.9284\n",
            "Epoch 10/10 | Train Loss: 0.2071 | Val Loss: 0.1964 | Val Acc: 0.9298\n",
            "Test Loss: 0.1963 | Test Acc: 0.9298\n",
            "Epoch 1/10 | Train Loss: 0.4138 | Val Loss: 0.2030 | Val Acc: 0.9313\n",
            "Epoch 2/10 | Train Loss: 0.2642 | Val Loss: 0.2018 | Val Acc: 0.9295\n",
            "Epoch 3/10 | Train Loss: 0.2489 | Val Loss: 0.2057 | Val Acc: 0.9287\n",
            "Epoch 4/10 | Train Loss: 0.2345 | Val Loss: 0.1904 | Val Acc: 0.9331\n",
            "Epoch 5/10 | Train Loss: 0.2308 | Val Loss: 0.1847 | Val Acc: 0.9320\n",
            "Epoch 6/10 | Train Loss: 0.2238 | Val Loss: 0.1887 | Val Acc: 0.9335\n",
            "Epoch 7/10 | Train Loss: 0.2235 | Val Loss: 0.1938 | Val Acc: 0.9346\n",
            "Epoch 8/10 | Train Loss: 0.2128 | Val Loss: 0.1836 | Val Acc: 0.9357\n",
            "Epoch 9/10 | Train Loss: 0.2151 | Val Loss: 0.1898 | Val Acc: 0.9298\n",
            "Epoch 10/10 | Train Loss: 0.2108 | Val Loss: 0.1834 | Val Acc: 0.9342\n",
            "Test Loss: 0.1833 | Test Acc: 0.9342\n",
            "Epoch 1/10 | Train Loss: 0.4617 | Val Loss: 0.2535 | Val Acc: 0.9144\n",
            "Epoch 2/10 | Train Loss: 0.2770 | Val Loss: 0.2304 | Val Acc: 0.9184\n",
            "Epoch 3/10 | Train Loss: 0.2514 | Val Loss: 0.1897 | Val Acc: 0.9335\n",
            "Epoch 4/10 | Train Loss: 0.2429 | Val Loss: 0.2094 | Val Acc: 0.9287\n",
            "Epoch 5/10 | Train Loss: 0.2352 | Val Loss: 0.1913 | Val Acc: 0.9298\n",
            "Epoch 6/10 | Train Loss: 0.2365 | Val Loss: 0.1932 | Val Acc: 0.9302\n",
            "Epoch 7/10 | Train Loss: 0.2265 | Val Loss: 0.1856 | Val Acc: 0.9339\n",
            "Epoch 8/10 | Train Loss: 0.2231 | Val Loss: 0.1947 | Val Acc: 0.9309\n",
            "Epoch 9/10 | Train Loss: 0.2272 | Val Loss: 0.1767 | Val Acc: 0.9375\n",
            "Epoch 10/10 | Train Loss: 0.2174 | Val Loss: 0.1889 | Val Acc: 0.9335\n",
            "Test Loss: 0.1888 | Test Acc: 0.9335\n",
            "Epoch 1/10 | Train Loss: 0.3944 | Val Loss: 0.2235 | Val Acc: 0.9177\n",
            "Epoch 2/10 | Train Loss: 0.2563 | Val Loss: 0.2019 | Val Acc: 0.9273\n",
            "Epoch 3/10 | Train Loss: 0.2372 | Val Loss: 0.1914 | Val Acc: 0.9335\n",
            "Epoch 4/10 | Train Loss: 0.2298 | Val Loss: 0.1978 | Val Acc: 0.9335\n",
            "Epoch 5/10 | Train Loss: 0.2201 | Val Loss: 0.1913 | Val Acc: 0.9302\n",
            "Epoch 6/10 | Train Loss: 0.2144 | Val Loss: 0.1984 | Val Acc: 0.9306\n",
            "Epoch 7/10 | Train Loss: 0.2139 | Val Loss: 0.2019 | Val Acc: 0.9247\n",
            "Epoch 8/10 | Train Loss: 0.2120 | Val Loss: 0.2025 | Val Acc: 0.9309\n",
            "Epoch 9/10 | Train Loss: 0.2122 | Val Loss: 0.1879 | Val Acc: 0.9353\n",
            "Epoch 10/10 | Train Loss: 0.2111 | Val Loss: 0.1803 | Val Acc: 0.9361\n",
            "Test Loss: 0.1802 | Test Acc: 0.9361\n",
            "Epoch 1/10 | Train Loss: 0.4243 | Val Loss: 0.2196 | Val Acc: 0.9273\n",
            "Epoch 2/10 | Train Loss: 0.2604 | Val Loss: 0.2197 | Val Acc: 0.9258\n",
            "Epoch 3/10 | Train Loss: 0.2394 | Val Loss: 0.1885 | Val Acc: 0.9331\n",
            "Epoch 4/10 | Train Loss: 0.2389 | Val Loss: 0.1925 | Val Acc: 0.9306\n",
            "Epoch 5/10 | Train Loss: 0.2235 | Val Loss: 0.1904 | Val Acc: 0.9295\n",
            "Epoch 6/10 | Train Loss: 0.2225 | Val Loss: 0.1955 | Val Acc: 0.9295\n",
            "Epoch 7/10 | Train Loss: 0.2176 | Val Loss: 0.2584 | Val Acc: 0.9100\n",
            "Epoch 8/10 | Train Loss: 0.2184 | Val Loss: 0.1998 | Val Acc: 0.9302\n",
            "Epoch 9/10 | Train Loss: 0.2154 | Val Loss: 0.1986 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2111 | Val Loss: 0.1887 | Val Acc: 0.9357\n",
            "Test Loss: 0.1886 | Test Acc: 0.9357\n",
            "Epoch 1/10 | Train Loss: 0.4387 | Val Loss: 0.2491 | Val Acc: 0.9096\n",
            "Epoch 2/10 | Train Loss: 0.2748 | Val Loss: 0.2071 | Val Acc: 0.9265\n",
            "Epoch 3/10 | Train Loss: 0.2607 | Val Loss: 0.2020 | Val Acc: 0.9284\n",
            "Epoch 4/10 | Train Loss: 0.2456 | Val Loss: 0.2297 | Val Acc: 0.9177\n",
            "Epoch 5/10 | Train Loss: 0.2338 | Val Loss: 0.2132 | Val Acc: 0.9214\n",
            "Epoch 6/10 | Train Loss: 0.2311 | Val Loss: 0.1942 | Val Acc: 0.9306\n",
            "Epoch 7/10 | Train Loss: 0.2247 | Val Loss: 0.2120 | Val Acc: 0.9258\n",
            "Epoch 8/10 | Train Loss: 0.2222 | Val Loss: 0.1968 | Val Acc: 0.9284\n",
            "Epoch 9/10 | Train Loss: 0.2220 | Val Loss: 0.2146 | Val Acc: 0.9225\n",
            "Epoch 10/10 | Train Loss: 0.2143 | Val Loss: 0.1940 | Val Acc: 0.9262\n",
            "Test Loss: 0.1939 | Test Acc: 0.9262\n",
            "Epoch 1/10 | Train Loss: 0.3990 | Val Loss: 0.2063 | Val Acc: 0.9273\n",
            "Epoch 2/10 | Train Loss: 0.2515 | Val Loss: 0.2019 | Val Acc: 0.9302\n",
            "Epoch 3/10 | Train Loss: 0.2400 | Val Loss: 0.2223 | Val Acc: 0.9240\n",
            "Epoch 4/10 | Train Loss: 0.2225 | Val Loss: 0.2035 | Val Acc: 0.9320\n",
            "Epoch 5/10 | Train Loss: 0.2215 | Val Loss: 0.2232 | Val Acc: 0.9181\n",
            "Epoch 6/10 | Train Loss: 0.2222 | Val Loss: 0.1996 | Val Acc: 0.9269\n",
            "Epoch 7/10 | Train Loss: 0.2145 | Val Loss: 0.1851 | Val Acc: 0.9313\n",
            "Epoch 8/10 | Train Loss: 0.2133 | Val Loss: 0.2086 | Val Acc: 0.9273\n",
            "Epoch 9/10 | Train Loss: 0.2155 | Val Loss: 0.1835 | Val Acc: 0.9353\n",
            "Epoch 10/10 | Train Loss: 0.2050 | Val Loss: 0.1901 | Val Acc: 0.9320\n",
            "Test Loss: 0.1900 | Test Acc: 0.9320\n",
            "Epoch 1/10 | Train Loss: 0.4348 | Val Loss: 0.2137 | Val Acc: 0.9206\n",
            "Epoch 2/10 | Train Loss: 0.2584 | Val Loss: 0.1905 | Val Acc: 0.9320\n",
            "Epoch 3/10 | Train Loss: 0.2468 | Val Loss: 0.2420 | Val Acc: 0.9078\n",
            "Epoch 4/10 | Train Loss: 0.2294 | Val Loss: 0.1968 | Val Acc: 0.9339\n",
            "Epoch 5/10 | Train Loss: 0.2310 | Val Loss: 0.1917 | Val Acc: 0.9353\n",
            "Epoch 6/10 | Train Loss: 0.2213 | Val Loss: 0.2100 | Val Acc: 0.9243\n",
            "Epoch 7/10 | Train Loss: 0.2243 | Val Loss: 0.1977 | Val Acc: 0.9265\n",
            "Epoch 8/10 | Train Loss: 0.2172 | Val Loss: 0.2085 | Val Acc: 0.9221\n",
            "Epoch 9/10 | Train Loss: 0.2168 | Val Loss: 0.1762 | Val Acc: 0.9375\n",
            "Epoch 10/10 | Train Loss: 0.2098 | Val Loss: 0.1963 | Val Acc: 0.9280\n",
            "Test Loss: 0.1963 | Test Acc: 0.9280\n",
            "Epoch 1/10 | Train Loss: 0.4443 | Val Loss: 0.2182 | Val Acc: 0.9284\n",
            "Epoch 2/10 | Train Loss: 0.2765 | Val Loss: 0.2306 | Val Acc: 0.9195\n",
            "Epoch 3/10 | Train Loss: 0.2539 | Val Loss: 0.2446 | Val Acc: 0.9107\n",
            "Epoch 4/10 | Train Loss: 0.2447 | Val Loss: 0.2038 | Val Acc: 0.9262\n",
            "Epoch 5/10 | Train Loss: 0.2391 | Val Loss: 0.1908 | Val Acc: 0.9346\n",
            "Epoch 6/10 | Train Loss: 0.2317 | Val Loss: 0.1808 | Val Acc: 0.9357\n",
            "Epoch 7/10 | Train Loss: 0.2245 | Val Loss: 0.1877 | Val Acc: 0.9328\n",
            "Epoch 8/10 | Train Loss: 0.2245 | Val Loss: 0.1896 | Val Acc: 0.9320\n",
            "Epoch 9/10 | Train Loss: 0.2250 | Val Loss: 0.1921 | Val Acc: 0.9269\n",
            "Epoch 10/10 | Train Loss: 0.2144 | Val Loss: 0.1960 | Val Acc: 0.9313\n",
            "Test Loss: 0.1959 | Test Acc: 0.9313\n",
            "Epoch 1/10 | Train Loss: 0.3229 | Val Loss: 0.2339 | Val Acc: 0.9199\n",
            "Epoch 2/10 | Train Loss: 0.2406 | Val Loss: 0.2242 | Val Acc: 0.9214\n",
            "Epoch 3/10 | Train Loss: 0.2328 | Val Loss: 0.1964 | Val Acc: 0.9284\n",
            "Epoch 4/10 | Train Loss: 0.2180 | Val Loss: 0.2023 | Val Acc: 0.9284\n",
            "Epoch 5/10 | Train Loss: 0.2211 | Val Loss: 0.1882 | Val Acc: 0.9331\n",
            "Epoch 6/10 | Train Loss: 0.2098 | Val Loss: 0.2493 | Val Acc: 0.9082\n",
            "Epoch 7/10 | Train Loss: 0.2126 | Val Loss: 0.1998 | Val Acc: 0.9328\n",
            "Epoch 8/10 | Train Loss: 0.2046 | Val Loss: 0.1809 | Val Acc: 0.9379\n",
            "Epoch 9/10 | Train Loss: 0.2066 | Val Loss: 0.1831 | Val Acc: 0.9361\n",
            "Epoch 10/10 | Train Loss: 0.2051 | Val Loss: 0.1930 | Val Acc: 0.9324\n",
            "Test Loss: 0.1929 | Test Acc: 0.9324\n",
            "Epoch 1/10 | Train Loss: 0.3308 | Val Loss: 0.2456 | Val Acc: 0.9104\n",
            "Epoch 2/10 | Train Loss: 0.2506 | Val Loss: 0.2100 | Val Acc: 0.9262\n",
            "Epoch 3/10 | Train Loss: 0.2347 | Val Loss: 0.2015 | Val Acc: 0.9291\n",
            "Epoch 4/10 | Train Loss: 0.2326 | Val Loss: 0.2021 | Val Acc: 0.9287\n",
            "Epoch 5/10 | Train Loss: 0.2268 | Val Loss: 0.1911 | Val Acc: 0.9324\n",
            "Epoch 6/10 | Train Loss: 0.2211 | Val Loss: 0.1788 | Val Acc: 0.9364\n",
            "Epoch 7/10 | Train Loss: 0.2109 | Val Loss: 0.2034 | Val Acc: 0.9291\n",
            "Epoch 8/10 | Train Loss: 0.2136 | Val Loss: 0.1896 | Val Acc: 0.9328\n",
            "Epoch 9/10 | Train Loss: 0.2108 | Val Loss: 0.1881 | Val Acc: 0.9328\n",
            "Epoch 10/10 | Train Loss: 0.2079 | Val Loss: 0.1928 | Val Acc: 0.9287\n",
            "Test Loss: 0.1927 | Test Acc: 0.9287\n",
            "Epoch 1/10 | Train Loss: 0.3523 | Val Loss: 0.2469 | Val Acc: 0.9133\n",
            "Epoch 2/10 | Train Loss: 0.2568 | Val Loss: 0.2008 | Val Acc: 0.9269\n",
            "Epoch 3/10 | Train Loss: 0.2411 | Val Loss: 0.2105 | Val Acc: 0.9284\n",
            "Epoch 4/10 | Train Loss: 0.2395 | Val Loss: 0.1979 | Val Acc: 0.9317\n",
            "Epoch 5/10 | Train Loss: 0.2332 | Val Loss: 0.2170 | Val Acc: 0.9210\n",
            "Epoch 6/10 | Train Loss: 0.2244 | Val Loss: 0.1836 | Val Acc: 0.9357\n",
            "Epoch 7/10 | Train Loss: 0.2197 | Val Loss: 0.2393 | Val Acc: 0.9210\n",
            "Epoch 8/10 | Train Loss: 0.2219 | Val Loss: 0.2067 | Val Acc: 0.9306\n",
            "Epoch 9/10 | Train Loss: 0.2172 | Val Loss: 0.1801 | Val Acc: 0.9361\n",
            "Epoch 10/10 | Train Loss: 0.2162 | Val Loss: 0.1838 | Val Acc: 0.9350\n",
            "Test Loss: 0.1837 | Test Acc: 0.9350\n",
            "Epoch 1/10 | Train Loss: 0.3284 | Val Loss: 0.2087 | Val Acc: 0.9217\n",
            "Epoch 2/10 | Train Loss: 0.2380 | Val Loss: 0.1951 | Val Acc: 0.9269\n",
            "Epoch 3/10 | Train Loss: 0.2268 | Val Loss: 0.1977 | Val Acc: 0.9335\n",
            "Epoch 4/10 | Train Loss: 0.2215 | Val Loss: 0.2187 | Val Acc: 0.9170\n",
            "Epoch 5/10 | Train Loss: 0.2259 | Val Loss: 0.2128 | Val Acc: 0.9206\n",
            "Epoch 6/10 | Train Loss: 0.2138 | Val Loss: 0.2142 | Val Acc: 0.9199\n",
            "Epoch 7/10 | Train Loss: 0.2137 | Val Loss: 0.1811 | Val Acc: 0.9361\n",
            "Epoch 8/10 | Train Loss: 0.2095 | Val Loss: 0.1812 | Val Acc: 0.9331\n",
            "Epoch 9/10 | Train Loss: 0.2052 | Val Loss: 0.1885 | Val Acc: 0.9309\n",
            "Epoch 10/10 | Train Loss: 0.2015 | Val Loss: 0.1946 | Val Acc: 0.9320\n",
            "Test Loss: 0.1946 | Test Acc: 0.9320\n",
            "Epoch 1/10 | Train Loss: 0.3296 | Val Loss: 0.2234 | Val Acc: 0.9195\n",
            "Epoch 2/10 | Train Loss: 0.2514 | Val Loss: 0.2170 | Val Acc: 0.9254\n",
            "Epoch 3/10 | Train Loss: 0.2421 | Val Loss: 0.1869 | Val Acc: 0.9353\n",
            "Epoch 4/10 | Train Loss: 0.2331 | Val Loss: 0.1928 | Val Acc: 0.9309\n",
            "Epoch 5/10 | Train Loss: 0.2260 | Val Loss: 0.2021 | Val Acc: 0.9269\n",
            "Epoch 6/10 | Train Loss: 0.2204 | Val Loss: 0.1977 | Val Acc: 0.9309\n",
            "Epoch 7/10 | Train Loss: 0.2165 | Val Loss: 0.2026 | Val Acc: 0.9276\n",
            "Epoch 8/10 | Train Loss: 0.2173 | Val Loss: 0.1916 | Val Acc: 0.9339\n",
            "Epoch 9/10 | Train Loss: 0.2178 | Val Loss: 0.2143 | Val Acc: 0.9262\n",
            "Epoch 10/10 | Train Loss: 0.2122 | Val Loss: 0.1846 | Val Acc: 0.9375\n",
            "Test Loss: 0.1845 | Test Acc: 0.9375\n",
            "Epoch 1/10 | Train Loss: 0.3585 | Val Loss: 0.2272 | Val Acc: 0.9192\n",
            "Epoch 2/10 | Train Loss: 0.2539 | Val Loss: 0.2140 | Val Acc: 0.9265\n",
            "Epoch 3/10 | Train Loss: 0.2455 | Val Loss: 0.2307 | Val Acc: 0.9177\n",
            "Epoch 4/10 | Train Loss: 0.2375 | Val Loss: 0.2222 | Val Acc: 0.9206\n",
            "Epoch 5/10 | Train Loss: 0.2305 | Val Loss: 0.2116 | Val Acc: 0.9199\n",
            "Epoch 6/10 | Train Loss: 0.2290 | Val Loss: 0.2372 | Val Acc: 0.9151\n",
            "Epoch 7/10 | Train Loss: 0.2246 | Val Loss: 0.1917 | Val Acc: 0.9335\n",
            "Epoch 8/10 | Train Loss: 0.2205 | Val Loss: 0.2031 | Val Acc: 0.9240\n",
            "Epoch 9/10 | Train Loss: 0.2202 | Val Loss: 0.1870 | Val Acc: 0.9353\n",
            "Epoch 10/10 | Train Loss: 0.2188 | Val Loss: 0.1953 | Val Acc: 0.9295\n",
            "Test Loss: 0.1952 | Test Acc: 0.9295\n",
            "Epoch 1/10 | Train Loss: 0.3278 | Val Loss: 0.1955 | Val Acc: 0.9335\n",
            "Epoch 2/10 | Train Loss: 0.2468 | Val Loss: 0.2107 | Val Acc: 0.9280\n",
            "Epoch 3/10 | Train Loss: 0.2327 | Val Loss: 0.2114 | Val Acc: 0.9298\n",
            "Epoch 4/10 | Train Loss: 0.2288 | Val Loss: 0.2063 | Val Acc: 0.9221\n",
            "Epoch 5/10 | Train Loss: 0.2277 | Val Loss: 0.1907 | Val Acc: 0.9306\n",
            "Epoch 6/10 | Train Loss: 0.2163 | Val Loss: 0.2120 | Val Acc: 0.9199\n",
            "Epoch 7/10 | Train Loss: 0.2128 | Val Loss: 0.2018 | Val Acc: 0.9251\n",
            "Epoch 8/10 | Train Loss: 0.2068 | Val Loss: 0.1921 | Val Acc: 0.9368\n",
            "Epoch 9/10 | Train Loss: 0.2037 | Val Loss: 0.2014 | Val Acc: 0.9276\n",
            "Epoch 10/10 | Train Loss: 0.2030 | Val Loss: 0.1955 | Val Acc: 0.9328\n",
            "Test Loss: 0.1954 | Test Acc: 0.9328\n",
            "Epoch 1/10 | Train Loss: 0.3406 | Val Loss: 0.2470 | Val Acc: 0.9107\n",
            "Epoch 2/10 | Train Loss: 0.2568 | Val Loss: 0.2044 | Val Acc: 0.9258\n",
            "Epoch 3/10 | Train Loss: 0.2441 | Val Loss: 0.2018 | Val Acc: 0.9287\n",
            "Epoch 4/10 | Train Loss: 0.2350 | Val Loss: 0.2040 | Val Acc: 0.9276\n",
            "Epoch 5/10 | Train Loss: 0.2257 | Val Loss: 0.1945 | Val Acc: 0.9309\n",
            "Epoch 6/10 | Train Loss: 0.2265 | Val Loss: 0.1940 | Val Acc: 0.9276\n",
            "Epoch 7/10 | Train Loss: 0.2103 | Val Loss: 0.1919 | Val Acc: 0.9324\n",
            "Epoch 8/10 | Train Loss: 0.2163 | Val Loss: 0.2077 | Val Acc: 0.9276\n",
            "Epoch 9/10 | Train Loss: 0.2193 | Val Loss: 0.1888 | Val Acc: 0.9331\n",
            "Epoch 10/10 | Train Loss: 0.2080 | Val Loss: 0.2027 | Val Acc: 0.9309\n",
            "Test Loss: 0.2026 | Test Acc: 0.9309\n",
            "Epoch 1/10 | Train Loss: 0.3577 | Val Loss: 0.2179 | Val Acc: 0.9232\n",
            "Epoch 2/10 | Train Loss: 0.2574 | Val Loss: 0.2024 | Val Acc: 0.9317\n",
            "Epoch 3/10 | Train Loss: 0.2467 | Val Loss: 0.1928 | Val Acc: 0.9302\n",
            "Epoch 4/10 | Train Loss: 0.2403 | Val Loss: 0.2071 | Val Acc: 0.9262\n",
            "Epoch 5/10 | Train Loss: 0.2309 | Val Loss: 0.2081 | Val Acc: 0.9240\n",
            "Epoch 6/10 | Train Loss: 0.2361 | Val Loss: 0.2044 | Val Acc: 0.9313\n",
            "Epoch 7/10 | Train Loss: 0.2317 | Val Loss: 0.1901 | Val Acc: 0.9291\n",
            "Epoch 8/10 | Train Loss: 0.2260 | Val Loss: 0.1900 | Val Acc: 0.9331\n",
            "Epoch 9/10 | Train Loss: 0.2189 | Val Loss: 0.1908 | Val Acc: 0.9302\n",
            "Epoch 10/10 | Train Loss: 0.2174 | Val Loss: 0.1827 | Val Acc: 0.9346\n",
            "Test Loss: 0.1826 | Test Acc: 0.9346\n",
            "Epoch 1/10 | Train Loss: 0.3389 | Val Loss: 0.2066 | Val Acc: 0.9240\n",
            "Epoch 2/10 | Train Loss: 0.2540 | Val Loss: 0.2111 | Val Acc: 0.9232\n",
            "Epoch 3/10 | Train Loss: 0.2420 | Val Loss: 0.2091 | Val Acc: 0.9254\n",
            "Epoch 4/10 | Train Loss: 0.2316 | Val Loss: 0.2121 | Val Acc: 0.9210\n",
            "Epoch 5/10 | Train Loss: 0.2260 | Val Loss: 0.1939 | Val Acc: 0.9276\n",
            "Epoch 6/10 | Train Loss: 0.2169 | Val Loss: 0.2031 | Val Acc: 0.9280\n",
            "Epoch 7/10 | Train Loss: 0.2163 | Val Loss: 0.2006 | Val Acc: 0.9291\n",
            "Epoch 8/10 | Train Loss: 0.2125 | Val Loss: 0.1941 | Val Acc: 0.9353\n",
            "Epoch 9/10 | Train Loss: 0.2080 | Val Loss: 0.1965 | Val Acc: 0.9324\n",
            "Epoch 10/10 | Train Loss: 0.2095 | Val Loss: 0.2049 | Val Acc: 0.9236\n",
            "Test Loss: 0.2048 | Test Acc: 0.9236\n",
            "Epoch 1/10 | Train Loss: 0.3579 | Val Loss: 0.2301 | Val Acc: 0.9203\n",
            "Epoch 2/10 | Train Loss: 0.2595 | Val Loss: 0.2146 | Val Acc: 0.9247\n",
            "Epoch 3/10 | Train Loss: 0.2471 | Val Loss: 0.1869 | Val Acc: 0.9331\n",
            "Epoch 4/10 | Train Loss: 0.2442 | Val Loss: 0.1980 | Val Acc: 0.9302\n",
            "Epoch 5/10 | Train Loss: 0.2361 | Val Loss: 0.1891 | Val Acc: 0.9353\n",
            "Epoch 6/10 | Train Loss: 0.2249 | Val Loss: 0.2077 | Val Acc: 0.9302\n",
            "Epoch 7/10 | Train Loss: 0.2225 | Val Loss: 0.2150 | Val Acc: 0.9188\n",
            "Epoch 8/10 | Train Loss: 0.2189 | Val Loss: 0.2017 | Val Acc: 0.9254\n",
            "Epoch 9/10 | Train Loss: 0.2190 | Val Loss: 0.2262 | Val Acc: 0.9188\n",
            "Epoch 10/10 | Train Loss: 0.2162 | Val Loss: 0.2089 | Val Acc: 0.9302\n",
            "Test Loss: 0.2089 | Test Acc: 0.9302\n",
            "Epoch 1/10 | Train Loss: 0.3812 | Val Loss: 0.2074 | Val Acc: 0.9258\n",
            "Epoch 2/10 | Train Loss: 0.2715 | Val Loss: 0.1958 | Val Acc: 0.9309\n",
            "Epoch 3/10 | Train Loss: 0.2532 | Val Loss: 0.2099 | Val Acc: 0.9232\n",
            "Epoch 4/10 | Train Loss: 0.2504 | Val Loss: 0.2395 | Val Acc: 0.9206\n",
            "Epoch 5/10 | Train Loss: 0.2458 | Val Loss: 0.1858 | Val Acc: 0.9372\n",
            "Epoch 6/10 | Train Loss: 0.2309 | Val Loss: 0.2046 | Val Acc: 0.9276\n",
            "Epoch 7/10 | Train Loss: 0.2371 | Val Loss: 0.2104 | Val Acc: 0.9251\n",
            "Epoch 8/10 | Train Loss: 0.2285 | Val Loss: 0.1959 | Val Acc: 0.9298\n",
            "Epoch 9/10 | Train Loss: 0.2263 | Val Loss: 0.2043 | Val Acc: 0.9258\n",
            "Epoch 10/10 | Train Loss: 0.2240 | Val Loss: 0.1990 | Val Acc: 0.9287\n",
            "Test Loss: 0.1990 | Test Acc: 0.9287\n",
            "Epoch 1/10 | Train Loss: 0.3306 | Val Loss: 0.2532 | Val Acc: 0.9118\n",
            "Epoch 2/10 | Train Loss: 0.2441 | Val Loss: 0.2568 | Val Acc: 0.9107\n",
            "Epoch 3/10 | Train Loss: 0.2382 | Val Loss: 0.1903 | Val Acc: 0.9375\n",
            "Epoch 4/10 | Train Loss: 0.2220 | Val Loss: 0.2015 | Val Acc: 0.9243\n",
            "Epoch 5/10 | Train Loss: 0.2243 | Val Loss: 0.1913 | Val Acc: 0.9353\n",
            "Epoch 6/10 | Train Loss: 0.2231 | Val Loss: 0.1948 | Val Acc: 0.9317\n",
            "Epoch 7/10 | Train Loss: 0.2162 | Val Loss: 0.2008 | Val Acc: 0.9276\n",
            "Epoch 8/10 | Train Loss: 0.2126 | Val Loss: 0.1874 | Val Acc: 0.9309\n",
            "Epoch 9/10 | Train Loss: 0.2071 | Val Loss: 0.1816 | Val Acc: 0.9375\n",
            "Epoch 10/10 | Train Loss: 0.2045 | Val Loss: 0.2026 | Val Acc: 0.9317\n",
            "Test Loss: 0.2026 | Test Acc: 0.9317\n",
            "Epoch 1/10 | Train Loss: 0.3431 | Val Loss: 0.2215 | Val Acc: 0.9254\n",
            "Epoch 2/10 | Train Loss: 0.2608 | Val Loss: 0.2582 | Val Acc: 0.9015\n",
            "Epoch 3/10 | Train Loss: 0.2461 | Val Loss: 0.2130 | Val Acc: 0.9221\n",
            "Epoch 4/10 | Train Loss: 0.2403 | Val Loss: 0.2134 | Val Acc: 0.9247\n",
            "Epoch 5/10 | Train Loss: 0.2357 | Val Loss: 0.1938 | Val Acc: 0.9335\n",
            "Epoch 6/10 | Train Loss: 0.2313 | Val Loss: 0.2094 | Val Acc: 0.9265\n",
            "Epoch 7/10 | Train Loss: 0.2267 | Val Loss: 0.1986 | Val Acc: 0.9284\n",
            "Epoch 8/10 | Train Loss: 0.2225 | Val Loss: 0.1963 | Val Acc: 0.9284\n",
            "Epoch 9/10 | Train Loss: 0.2166 | Val Loss: 0.1864 | Val Acc: 0.9331\n",
            "Epoch 10/10 | Train Loss: 0.2128 | Val Loss: 0.1942 | Val Acc: 0.9273\n",
            "Test Loss: 0.1941 | Test Acc: 0.9273\n",
            "Epoch 1/10 | Train Loss: 0.3622 | Val Loss: 0.2036 | Val Acc: 0.9295\n",
            "Epoch 2/10 | Train Loss: 0.2706 | Val Loss: 0.2404 | Val Acc: 0.9140\n",
            "Epoch 3/10 | Train Loss: 0.2592 | Val Loss: 0.2295 | Val Acc: 0.9159\n",
            "Epoch 4/10 | Train Loss: 0.2420 | Val Loss: 0.2136 | Val Acc: 0.9247\n",
            "Epoch 5/10 | Train Loss: 0.2402 | Val Loss: 0.2048 | Val Acc: 0.9243\n",
            "Epoch 6/10 | Train Loss: 0.2375 | Val Loss: 0.2169 | Val Acc: 0.9265\n",
            "Epoch 7/10 | Train Loss: 0.2330 | Val Loss: 0.2233 | Val Acc: 0.9225\n",
            "Epoch 8/10 | Train Loss: 0.2343 | Val Loss: 0.1958 | Val Acc: 0.9251\n",
            "Epoch 9/10 | Train Loss: 0.2274 | Val Loss: 0.2034 | Val Acc: 0.9284\n",
            "Epoch 10/10 | Train Loss: 0.2233 | Val Loss: 0.2416 | Val Acc: 0.9144\n",
            "Test Loss: 0.2415 | Test Acc: 0.9144\n",
            "Epoch 1/10 | Train Loss: 0.3236 | Val Loss: 0.2015 | Val Acc: 0.9254\n",
            "Epoch 2/10 | Train Loss: 0.2583 | Val Loss: 0.2254 | Val Acc: 0.9192\n",
            "Epoch 3/10 | Train Loss: 0.2323 | Val Loss: 0.1973 | Val Acc: 0.9284\n",
            "Epoch 4/10 | Train Loss: 0.2293 | Val Loss: 0.2224 | Val Acc: 0.9225\n",
            "Epoch 5/10 | Train Loss: 0.2229 | Val Loss: 0.1928 | Val Acc: 0.9291\n",
            "Epoch 6/10 | Train Loss: 0.2229 | Val Loss: 0.2126 | Val Acc: 0.9195\n",
            "Epoch 7/10 | Train Loss: 0.2155 | Val Loss: 0.2016 | Val Acc: 0.9251\n",
            "Epoch 8/10 | Train Loss: 0.2149 | Val Loss: 0.2089 | Val Acc: 0.9269\n",
            "Epoch 9/10 | Train Loss: 0.2091 | Val Loss: 0.2029 | Val Acc: 0.9302\n",
            "Epoch 10/10 | Train Loss: 0.2090 | Val Loss: 0.2025 | Val Acc: 0.9295\n",
            "Test Loss: 0.2024 | Test Acc: 0.9295\n",
            "Epoch 1/10 | Train Loss: 0.3404 | Val Loss: 0.2499 | Val Acc: 0.9107\n",
            "Epoch 2/10 | Train Loss: 0.2615 | Val Loss: 0.2194 | Val Acc: 0.9184\n",
            "Epoch 3/10 | Train Loss: 0.2510 | Val Loss: 0.2169 | Val Acc: 0.9258\n",
            "Epoch 4/10 | Train Loss: 0.2349 | Val Loss: 0.2025 | Val Acc: 0.9306\n",
            "Epoch 5/10 | Train Loss: 0.2319 | Val Loss: 0.2092 | Val Acc: 0.9199\n",
            "Epoch 6/10 | Train Loss: 0.2262 | Val Loss: 0.2020 | Val Acc: 0.9306\n",
            "Epoch 7/10 | Train Loss: 0.2254 | Val Loss: 0.1892 | Val Acc: 0.9357\n",
            "Epoch 8/10 | Train Loss: 0.2229 | Val Loss: 0.2374 | Val Acc: 0.9107\n",
            "Epoch 9/10 | Train Loss: 0.2181 | Val Loss: 0.2101 | Val Acc: 0.9240\n",
            "Epoch 10/10 | Train Loss: 0.2158 | Val Loss: 0.1986 | Val Acc: 0.9298\n",
            "Test Loss: 0.1985 | Test Acc: 0.9298\n",
            "Epoch 1/10 | Train Loss: 0.3710 | Val Loss: 0.2446 | Val Acc: 0.9155\n",
            "Epoch 2/10 | Train Loss: 0.2776 | Val Loss: 0.2286 | Val Acc: 0.9155\n",
            "Epoch 3/10 | Train Loss: 0.2604 | Val Loss: 0.2087 | Val Acc: 0.9258\n",
            "Epoch 4/10 | Train Loss: 0.2485 | Val Loss: 0.1866 | Val Acc: 0.9342\n",
            "Epoch 5/10 | Train Loss: 0.2455 | Val Loss: 0.2167 | Val Acc: 0.9251\n",
            "Epoch 6/10 | Train Loss: 0.2371 | Val Loss: 0.2014 | Val Acc: 0.9298\n",
            "Epoch 7/10 | Train Loss: 0.2354 | Val Loss: 0.1954 | Val Acc: 0.9342\n",
            "Epoch 8/10 | Train Loss: 0.2333 | Val Loss: 0.1950 | Val Acc: 0.9309\n",
            "Epoch 9/10 | Train Loss: 0.2216 | Val Loss: 0.1934 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2256 | Val Loss: 0.2087 | Val Acc: 0.9247\n",
            "Test Loss: 0.2086 | Test Acc: 0.9247\n",
            "Epoch 1/10 | Train Loss: 0.3409 | Val Loss: 0.2876 | Val Acc: 0.8964\n",
            "Epoch 2/10 | Train Loss: 0.2584 | Val Loss: 0.2478 | Val Acc: 0.9082\n",
            "Epoch 3/10 | Train Loss: 0.2396 | Val Loss: 0.1975 | Val Acc: 0.9298\n",
            "Epoch 4/10 | Train Loss: 0.2324 | Val Loss: 0.1977 | Val Acc: 0.9302\n",
            "Epoch 5/10 | Train Loss: 0.2236 | Val Loss: 0.2257 | Val Acc: 0.9177\n",
            "Epoch 6/10 | Train Loss: 0.2215 | Val Loss: 0.1885 | Val Acc: 0.9331\n",
            "Epoch 7/10 | Train Loss: 0.2184 | Val Loss: 0.2046 | Val Acc: 0.9214\n",
            "Epoch 8/10 | Train Loss: 0.2146 | Val Loss: 0.1819 | Val Acc: 0.9331\n",
            "Epoch 9/10 | Train Loss: 0.2134 | Val Loss: 0.2023 | Val Acc: 0.9280\n",
            "Epoch 10/10 | Train Loss: 0.2075 | Val Loss: 0.1972 | Val Acc: 0.9313\n",
            "Test Loss: 0.1972 | Test Acc: 0.9313\n",
            "Epoch 1/10 | Train Loss: 0.3735 | Val Loss: 0.2474 | Val Acc: 0.9159\n",
            "Epoch 2/10 | Train Loss: 0.2662 | Val Loss: 0.1937 | Val Acc: 0.9331\n",
            "Epoch 3/10 | Train Loss: 0.2448 | Val Loss: 0.2245 | Val Acc: 0.9214\n",
            "Epoch 4/10 | Train Loss: 0.2433 | Val Loss: 0.2078 | Val Acc: 0.9313\n",
            "Epoch 5/10 | Train Loss: 0.2378 | Val Loss: 0.2019 | Val Acc: 0.9265\n",
            "Epoch 6/10 | Train Loss: 0.2339 | Val Loss: 0.1988 | Val Acc: 0.9269\n",
            "Epoch 7/10 | Train Loss: 0.2346 | Val Loss: 0.2037 | Val Acc: 0.9276\n",
            "Epoch 8/10 | Train Loss: 0.2253 | Val Loss: 0.2083 | Val Acc: 0.9313\n",
            "Epoch 9/10 | Train Loss: 0.2239 | Val Loss: 0.1944 | Val Acc: 0.9302\n",
            "Epoch 10/10 | Train Loss: 0.2173 | Val Loss: 0.1938 | Val Acc: 0.9287\n",
            "Test Loss: 0.1937 | Test Acc: 0.9287\n",
            "Epoch 1/10 | Train Loss: 0.3659 | Val Loss: 0.2438 | Val Acc: 0.9155\n",
            "Epoch 2/10 | Train Loss: 0.2679 | Val Loss: 0.2130 | Val Acc: 0.9287\n",
            "Epoch 3/10 | Train Loss: 0.2642 | Val Loss: 0.2224 | Val Acc: 0.9243\n",
            "Epoch 4/10 | Train Loss: 0.2486 | Val Loss: 0.2201 | Val Acc: 0.9265\n",
            "Epoch 5/10 | Train Loss: 0.2450 | Val Loss: 0.2165 | Val Acc: 0.9236\n",
            "Epoch 6/10 | Train Loss: 0.2437 | Val Loss: 0.2115 | Val Acc: 0.9273\n",
            "Epoch 7/10 | Train Loss: 0.2336 | Val Loss: 0.2054 | Val Acc: 0.9276\n",
            "Epoch 8/10 | Train Loss: 0.2445 | Val Loss: 0.1913 | Val Acc: 0.9324\n",
            "Epoch 9/10 | Train Loss: 0.2315 | Val Loss: 0.1994 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2320 | Val Loss: 0.1959 | Val Acc: 0.9342\n",
            "Test Loss: 0.1958 | Test Acc: 0.9342\n",
            "Epoch 1/10 | Train Loss: 0.3387 | Val Loss: 0.2049 | Val Acc: 0.9265\n",
            "Epoch 2/10 | Train Loss: 0.2603 | Val Loss: 0.2055 | Val Acc: 0.9236\n",
            "Epoch 3/10 | Train Loss: 0.2427 | Val Loss: 0.2254 | Val Acc: 0.9217\n",
            "Epoch 4/10 | Train Loss: 0.2390 | Val Loss: 0.2152 | Val Acc: 0.9280\n",
            "Epoch 5/10 | Train Loss: 0.2258 | Val Loss: 0.1969 | Val Acc: 0.9291\n",
            "Epoch 6/10 | Train Loss: 0.2275 | Val Loss: 0.2067 | Val Acc: 0.9243\n",
            "Epoch 7/10 | Train Loss: 0.2179 | Val Loss: 0.1911 | Val Acc: 0.9302\n",
            "Epoch 8/10 | Train Loss: 0.2163 | Val Loss: 0.1801 | Val Acc: 0.9375\n",
            "Epoch 9/10 | Train Loss: 0.2194 | Val Loss: 0.1905 | Val Acc: 0.9276\n",
            "Epoch 10/10 | Train Loss: 0.2155 | Val Loss: 0.2541 | Val Acc: 0.9129\n",
            "Test Loss: 0.2540 | Test Acc: 0.9129\n",
            "Epoch 1/10 | Train Loss: 0.3677 | Val Loss: 0.2556 | Val Acc: 0.9111\n",
            "Epoch 2/10 | Train Loss: 0.2724 | Val Loss: 0.2332 | Val Acc: 0.9192\n",
            "Epoch 3/10 | Train Loss: 0.2565 | Val Loss: 0.2015 | Val Acc: 0.9331\n",
            "Epoch 4/10 | Train Loss: 0.2422 | Val Loss: 0.2323 | Val Acc: 0.9184\n",
            "Epoch 5/10 | Train Loss: 0.2433 | Val Loss: 0.2003 | Val Acc: 0.9302\n",
            "Epoch 6/10 | Train Loss: 0.2318 | Val Loss: 0.2055 | Val Acc: 0.9284\n",
            "Epoch 7/10 | Train Loss: 0.2297 | Val Loss: 0.2062 | Val Acc: 0.9269\n",
            "Epoch 8/10 | Train Loss: 0.2331 | Val Loss: 0.2049 | Val Acc: 0.9298\n",
            "Epoch 9/10 | Train Loss: 0.2267 | Val Loss: 0.1953 | Val Acc: 0.9320\n",
            "Epoch 10/10 | Train Loss: 0.2292 | Val Loss: 0.1983 | Val Acc: 0.9251\n",
            "Test Loss: 0.1982 | Test Acc: 0.9251\n",
            "Epoch 1/10 | Train Loss: 0.3652 | Val Loss: 0.2157 | Val Acc: 0.9206\n",
            "Epoch 2/10 | Train Loss: 0.2760 | Val Loss: 0.2057 | Val Acc: 0.9298\n",
            "Epoch 3/10 | Train Loss: 0.2610 | Val Loss: 0.2121 | Val Acc: 0.9254\n",
            "Epoch 4/10 | Train Loss: 0.2508 | Val Loss: 0.2523 | Val Acc: 0.9107\n",
            "Epoch 5/10 | Train Loss: 0.2549 | Val Loss: 0.2025 | Val Acc: 0.9269\n",
            "Epoch 6/10 | Train Loss: 0.2379 | Val Loss: 0.1898 | Val Acc: 0.9328\n",
            "Epoch 7/10 | Train Loss: 0.2384 | Val Loss: 0.1954 | Val Acc: 0.9324\n",
            "Epoch 8/10 | Train Loss: 0.2323 | Val Loss: 0.1985 | Val Acc: 0.9291\n",
            "Epoch 9/10 | Train Loss: 0.2298 | Val Loss: 0.1919 | Val Acc: 0.9306\n",
            "Epoch 10/10 | Train Loss: 0.2282 | Val Loss: 0.1976 | Val Acc: 0.9295\n",
            "Test Loss: 0.1975 | Test Acc: 0.9295\n",
            "Epoch 1/10 | Train Loss: 0.3316 | Val Loss: 0.2225 | Val Acc: 0.9188\n",
            "Epoch 2/10 | Train Loss: 0.2583 | Val Loss: 0.2153 | Val Acc: 0.9287\n",
            "Epoch 3/10 | Train Loss: 0.2355 | Val Loss: 0.2414 | Val Acc: 0.9104\n",
            "Epoch 4/10 | Train Loss: 0.2380 | Val Loss: 0.2175 | Val Acc: 0.9229\n",
            "Epoch 5/10 | Train Loss: 0.2240 | Val Loss: 0.1929 | Val Acc: 0.9306\n",
            "Epoch 6/10 | Train Loss: 0.2222 | Val Loss: 0.1932 | Val Acc: 0.9317\n",
            "Epoch 7/10 | Train Loss: 0.2244 | Val Loss: 0.3162 | Val Acc: 0.8902\n",
            "Epoch 8/10 | Train Loss: 0.2173 | Val Loss: 0.2235 | Val Acc: 0.9251\n",
            "Epoch 9/10 | Train Loss: 0.2116 | Val Loss: 0.1892 | Val Acc: 0.9368\n",
            "Epoch 10/10 | Train Loss: 0.2117 | Val Loss: 0.1864 | Val Acc: 0.9335\n",
            "Test Loss: 0.1863 | Test Acc: 0.9335\n",
            "Epoch 1/10 | Train Loss: 0.3661 | Val Loss: 0.2184 | Val Acc: 0.9240\n",
            "Epoch 2/10 | Train Loss: 0.2682 | Val Loss: 0.2030 | Val Acc: 0.9298\n",
            "Epoch 3/10 | Train Loss: 0.2627 | Val Loss: 0.2356 | Val Acc: 0.9170\n",
            "Epoch 4/10 | Train Loss: 0.2511 | Val Loss: 0.2037 | Val Acc: 0.9276\n",
            "Epoch 5/10 | Train Loss: 0.2408 | Val Loss: 0.1951 | Val Acc: 0.9295\n",
            "Epoch 6/10 | Train Loss: 0.2313 | Val Loss: 0.2074 | Val Acc: 0.9276\n",
            "Epoch 7/10 | Train Loss: 0.2326 | Val Loss: 0.2122 | Val Acc: 0.9243\n",
            "Epoch 8/10 | Train Loss: 0.2229 | Val Loss: 0.2163 | Val Acc: 0.9280\n",
            "Epoch 9/10 | Train Loss: 0.2206 | Val Loss: 0.2061 | Val Acc: 0.9262\n",
            "Epoch 10/10 | Train Loss: 0.2260 | Val Loss: 0.2076 | Val Acc: 0.9229\n",
            "Test Loss: 0.2076 | Test Acc: 0.9229\n",
            "Epoch 1/10 | Train Loss: 0.4101 | Val Loss: 0.2330 | Val Acc: 0.9184\n",
            "Epoch 2/10 | Train Loss: 0.2783 | Val Loss: 0.2202 | Val Acc: 0.9243\n",
            "Epoch 3/10 | Train Loss: 0.2653 | Val Loss: 0.2403 | Val Acc: 0.9144\n",
            "Epoch 4/10 | Train Loss: 0.2559 | Val Loss: 0.2071 | Val Acc: 0.9287\n",
            "Epoch 5/10 | Train Loss: 0.2566 | Val Loss: 0.2096 | Val Acc: 0.9298\n",
            "Epoch 6/10 | Train Loss: 0.2483 | Val Loss: 0.2071 | Val Acc: 0.9262\n",
            "Epoch 7/10 | Train Loss: 0.2389 | Val Loss: 0.1979 | Val Acc: 0.9291\n",
            "Epoch 8/10 | Train Loss: 0.2305 | Val Loss: 0.2088 | Val Acc: 0.9269\n",
            "Epoch 9/10 | Train Loss: 0.2296 | Val Loss: 0.2197 | Val Acc: 0.9265\n",
            "Epoch 10/10 | Train Loss: 0.2314 | Val Loss: 0.1974 | Val Acc: 0.9302\n",
            "Test Loss: 0.1973 | Test Acc: 0.9302\n",
            "Epoch 1/10 | Train Loss: 0.3132 | Val Loss: 0.2334 | Val Acc: 0.9210\n",
            "Epoch 2/10 | Train Loss: 0.2673 | Val Loss: 0.2886 | Val Acc: 0.8924\n",
            "Epoch 3/10 | Train Loss: 0.2484 | Val Loss: 0.1921 | Val Acc: 0.9324\n",
            "Epoch 4/10 | Train Loss: 0.2436 | Val Loss: 0.2559 | Val Acc: 0.9170\n",
            "Epoch 5/10 | Train Loss: 0.2563 | Val Loss: 0.2699 | Val Acc: 0.9096\n",
            "Epoch 6/10 | Train Loss: 0.2449 | Val Loss: 0.1951 | Val Acc: 0.9302\n",
            "Epoch 7/10 | Train Loss: 0.2292 | Val Loss: 0.2377 | Val Acc: 0.9188\n",
            "Epoch 8/10 | Train Loss: 0.2313 | Val Loss: 0.2159 | Val Acc: 0.9236\n",
            "Epoch 9/10 | Train Loss: 0.2642 | Val Loss: 0.1971 | Val Acc: 0.9313\n",
            "Epoch 10/10 | Train Loss: 0.2218 | Val Loss: 0.2064 | Val Acc: 0.9276\n",
            "Test Loss: 0.2063 | Test Acc: 0.9276\n",
            "Epoch 1/10 | Train Loss: 0.3494 | Val Loss: 0.2374 | Val Acc: 0.9126\n",
            "Epoch 2/10 | Train Loss: 0.2868 | Val Loss: 0.2364 | Val Acc: 0.9166\n",
            "Epoch 3/10 | Train Loss: 0.2637 | Val Loss: 0.2384 | Val Acc: 0.9151\n",
            "Epoch 4/10 | Train Loss: 0.2522 | Val Loss: 0.2167 | Val Acc: 0.9225\n",
            "Epoch 5/10 | Train Loss: 0.2561 | Val Loss: 0.2424 | Val Acc: 0.9166\n",
            "Epoch 6/10 | Train Loss: 0.2513 | Val Loss: 0.2011 | Val Acc: 0.9273\n",
            "Epoch 7/10 | Train Loss: 0.2442 | Val Loss: 0.2410 | Val Acc: 0.9276\n",
            "Epoch 8/10 | Train Loss: 0.2463 | Val Loss: 0.2117 | Val Acc: 0.9273\n",
            "Epoch 9/10 | Train Loss: 0.2346 | Val Loss: 0.2166 | Val Acc: 0.9302\n",
            "Epoch 10/10 | Train Loss: 0.2818 | Val Loss: 0.2143 | Val Acc: 0.9295\n",
            "Test Loss: 0.2143 | Test Acc: 0.9295\n",
            "Epoch 1/10 | Train Loss: 0.3497 | Val Loss: 0.3077 | Val Acc: 0.8916\n",
            "Epoch 2/10 | Train Loss: 0.2782 | Val Loss: 0.2258 | Val Acc: 0.9217\n",
            "Epoch 3/10 | Train Loss: 0.2686 | Val Loss: 0.2195 | Val Acc: 0.9210\n",
            "Epoch 4/10 | Train Loss: 0.2797 | Val Loss: 0.2437 | Val Acc: 0.9089\n",
            "Epoch 5/10 | Train Loss: 0.2778 | Val Loss: 0.2897 | Val Acc: 0.9015\n",
            "Epoch 6/10 | Train Loss: 0.2677 | Val Loss: 0.2096 | Val Acc: 0.9247\n",
            "Epoch 7/10 | Train Loss: 0.2607 | Val Loss: 0.2246 | Val Acc: 0.9243\n",
            "Epoch 8/10 | Train Loss: 0.2640 | Val Loss: 0.2066 | Val Acc: 0.9302\n",
            "Epoch 9/10 | Train Loss: 0.2704 | Val Loss: 0.2276 | Val Acc: 0.9265\n",
            "Epoch 10/10 | Train Loss: 0.2570 | Val Loss: 0.2405 | Val Acc: 0.9225\n",
            "Test Loss: 0.2404 | Test Acc: 0.9225\n",
            "Epoch 1/10 | Train Loss: 0.3158 | Val Loss: 0.2102 | Val Acc: 0.9240\n",
            "Epoch 2/10 | Train Loss: 0.2671 | Val Loss: 0.2395 | Val Acc: 0.9151\n",
            "Epoch 3/10 | Train Loss: 0.2442 | Val Loss: 0.2479 | Val Acc: 0.9118\n",
            "Epoch 4/10 | Train Loss: 0.2453 | Val Loss: 0.2333 | Val Acc: 0.9166\n",
            "Epoch 5/10 | Train Loss: 0.2463 | Val Loss: 0.2204 | Val Acc: 0.9269\n",
            "Epoch 6/10 | Train Loss: 0.2379 | Val Loss: 0.2691 | Val Acc: 0.9034\n",
            "Epoch 7/10 | Train Loss: 0.2879 | Val Loss: 0.2040 | Val Acc: 0.9309\n",
            "Epoch 8/10 | Train Loss: 0.2395 | Val Loss: 0.2061 | Val Acc: 0.9291\n",
            "Epoch 9/10 | Train Loss: 0.2298 | Val Loss: 0.1986 | Val Acc: 0.9295\n",
            "Epoch 10/10 | Train Loss: 0.2251 | Val Loss: 0.1976 | Val Acc: 0.9324\n",
            "Test Loss: 0.1975 | Test Acc: 0.9324\n",
            "Epoch 1/10 | Train Loss: 0.3398 | Val Loss: 0.2189 | Val Acc: 0.9221\n",
            "Epoch 2/10 | Train Loss: 0.2665 | Val Loss: 0.2223 | Val Acc: 0.9280\n",
            "Epoch 3/10 | Train Loss: 0.2598 | Val Loss: 0.2685 | Val Acc: 0.9089\n",
            "Epoch 4/10 | Train Loss: 0.2593 | Val Loss: 0.2362 | Val Acc: 0.9137\n",
            "Epoch 5/10 | Train Loss: 0.2524 | Val Loss: 0.2236 | Val Acc: 0.9195\n",
            "Epoch 6/10 | Train Loss: 0.2462 | Val Loss: 0.2443 | Val Acc: 0.9140\n",
            "Epoch 7/10 | Train Loss: 0.2468 | Val Loss: 0.2165 | Val Acc: 0.9287\n",
            "Epoch 8/10 | Train Loss: 0.2444 | Val Loss: 0.2014 | Val Acc: 0.9339\n",
            "Epoch 9/10 | Train Loss: 0.2468 | Val Loss: 0.2218 | Val Acc: 0.9284\n",
            "Epoch 10/10 | Train Loss: 0.2855 | Val Loss: 0.2440 | Val Acc: 0.9118\n",
            "Test Loss: 0.2439 | Test Acc: 0.9118\n",
            "Epoch 1/10 | Train Loss: 0.3502 | Val Loss: 0.2736 | Val Acc: 0.9067\n",
            "Epoch 2/10 | Train Loss: 0.2856 | Val Loss: 0.2963 | Val Acc: 0.9019\n",
            "Epoch 3/10 | Train Loss: 0.2678 | Val Loss: 0.2312 | Val Acc: 0.9225\n",
            "Epoch 4/10 | Train Loss: 0.2662 | Val Loss: 0.2548 | Val Acc: 0.9177\n",
            "Epoch 5/10 | Train Loss: 0.2669 | Val Loss: 0.2122 | Val Acc: 0.9309\n",
            "Epoch 6/10 | Train Loss: 0.2607 | Val Loss: 0.2450 | Val Acc: 0.9173\n",
            "Epoch 7/10 | Train Loss: 0.2658 | Val Loss: 0.2161 | Val Acc: 0.9284\n",
            "Epoch 8/10 | Train Loss: 0.2504 | Val Loss: 0.2277 | Val Acc: 0.9269\n",
            "Epoch 9/10 | Train Loss: 0.2569 | Val Loss: 0.2417 | Val Acc: 0.9199\n",
            "Epoch 10/10 | Train Loss: 0.2538 | Val Loss: 0.2500 | Val Acc: 0.9173\n",
            "Test Loss: 0.2499 | Test Acc: 0.9173\n",
            "Epoch 1/10 | Train Loss: 0.3249 | Val Loss: 0.2371 | Val Acc: 0.9133\n",
            "Epoch 2/10 | Train Loss: 0.2538 | Val Loss: 0.2215 | Val Acc: 0.9217\n",
            "Epoch 3/10 | Train Loss: 0.2672 | Val Loss: 0.2222 | Val Acc: 0.9217\n",
            "Epoch 4/10 | Train Loss: 0.2340 | Val Loss: 0.2542 | Val Acc: 0.9082\n",
            "Epoch 5/10 | Train Loss: 0.2338 | Val Loss: 0.2229 | Val Acc: 0.9232\n",
            "Epoch 6/10 | Train Loss: 0.2421 | Val Loss: 0.2178 | Val Acc: 0.9217\n",
            "Epoch 7/10 | Train Loss: 0.2307 | Val Loss: 0.2927 | Val Acc: 0.9045\n",
            "Epoch 8/10 | Train Loss: 0.2241 | Val Loss: 0.2185 | Val Acc: 0.9265\n",
            "Epoch 9/10 | Train Loss: 0.2281 | Val Loss: 0.2248 | Val Acc: 0.9225\n",
            "Epoch 10/10 | Train Loss: 0.2383 | Val Loss: 0.2195 | Val Acc: 0.9243\n",
            "Test Loss: 0.2194 | Test Acc: 0.9243\n",
            "Epoch 1/10 | Train Loss: 0.3209 | Val Loss: 0.3329 | Val Acc: 0.8788\n",
            "Epoch 2/10 | Train Loss: 0.2604 | Val Loss: 0.2011 | Val Acc: 0.9287\n",
            "Epoch 3/10 | Train Loss: 0.2610 | Val Loss: 0.3509 | Val Acc: 0.8806\n",
            "Epoch 4/10 | Train Loss: 0.2641 | Val Loss: 0.2381 | Val Acc: 0.9173\n",
            "Epoch 5/10 | Train Loss: 0.2421 | Val Loss: 0.1953 | Val Acc: 0.9287\n",
            "Epoch 6/10 | Train Loss: 0.2342 | Val Loss: 0.2114 | Val Acc: 0.9262\n",
            "Epoch 7/10 | Train Loss: 0.2396 | Val Loss: 0.2290 | Val Acc: 0.9129\n",
            "Epoch 8/10 | Train Loss: 0.2417 | Val Loss: 0.2424 | Val Acc: 0.9177\n",
            "Epoch 9/10 | Train Loss: 0.2444 | Val Loss: 0.2272 | Val Acc: 0.9229\n",
            "Epoch 10/10 | Train Loss: 0.2452 | Val Loss: 0.2094 | Val Acc: 0.9225\n",
            "Test Loss: 0.2093 | Test Acc: 0.9225\n",
            "Epoch 1/10 | Train Loss: 0.3436 | Val Loss: 0.3160 | Val Acc: 0.8832\n",
            "Epoch 2/10 | Train Loss: 0.2847 | Val Loss: 0.2909 | Val Acc: 0.9001\n",
            "Epoch 3/10 | Train Loss: 0.2731 | Val Loss: 0.2345 | Val Acc: 0.9214\n",
            "Epoch 4/10 | Train Loss: 0.2654 | Val Loss: 0.2103 | Val Acc: 0.9291\n",
            "Epoch 5/10 | Train Loss: 0.2652 | Val Loss: 0.3357 | Val Acc: 0.9026\n",
            "Epoch 6/10 | Train Loss: 0.2628 | Val Loss: 0.2274 | Val Acc: 0.9273\n",
            "Epoch 7/10 | Train Loss: 0.2547 | Val Loss: 0.2290 | Val Acc: 0.9155\n",
            "Epoch 8/10 | Train Loss: 0.2514 | Val Loss: 0.2286 | Val Acc: 0.9221\n",
            "Epoch 9/10 | Train Loss: 0.2703 | Val Loss: 0.2260 | Val Acc: 0.9181\n",
            "Epoch 10/10 | Train Loss: 0.2596 | Val Loss: 0.2104 | Val Acc: 0.9291\n",
            "Test Loss: 0.2103 | Test Acc: 0.9291\n",
            "Epoch 1/10 | Train Loss: 0.3444 | Val Loss: 0.2258 | Val Acc: 0.9240\n",
            "Epoch 2/10 | Train Loss: 0.2720 | Val Loss: 0.2459 | Val Acc: 0.9166\n",
            "Epoch 3/10 | Train Loss: 0.2778 | Val Loss: 0.2118 | Val Acc: 0.9276\n",
            "Epoch 4/10 | Train Loss: 0.2792 | Val Loss: 0.4238 | Val Acc: 0.8714\n",
            "Epoch 5/10 | Train Loss: 0.3571 | Val Loss: 0.2463 | Val Acc: 0.9111\n",
            "Epoch 6/10 | Train Loss: 0.2693 | Val Loss: 0.2385 | Val Acc: 0.9126\n",
            "Epoch 7/10 | Train Loss: 0.2648 | Val Loss: 0.1985 | Val Acc: 0.9309\n",
            "Epoch 8/10 | Train Loss: 0.2364 | Val Loss: 0.2012 | Val Acc: 0.9280\n",
            "Epoch 9/10 | Train Loss: 0.2275 | Val Loss: 0.2659 | Val Acc: 0.9104\n",
            "Epoch 10/10 | Train Loss: 0.2370 | Val Loss: 0.2075 | Val Acc: 0.9309\n",
            "Test Loss: 0.2075 | Test Acc: 0.9309\n",
            "Epoch 1/10 | Train Loss: 0.3647 | Val Loss: 0.2341 | Val Acc: 0.9214\n",
            "Epoch 2/10 | Train Loss: 0.2948 | Val Loss: 0.2142 | Val Acc: 0.9258\n",
            "Epoch 3/10 | Train Loss: 0.2863 | Val Loss: 0.2078 | Val Acc: 0.9295\n",
            "Epoch 4/10 | Train Loss: 0.2777 | Val Loss: 0.2271 | Val Acc: 0.9254\n",
            "Epoch 5/10 | Train Loss: 0.2627 | Val Loss: 0.2650 | Val Acc: 0.9159\n",
            "Epoch 6/10 | Train Loss: 0.3336 | Val Loss: 0.2255 | Val Acc: 0.9291\n",
            "Epoch 7/10 | Train Loss: 0.3381 | Val Loss: 0.2505 | Val Acc: 0.9056\n",
            "Epoch 8/10 | Train Loss: 0.2888 | Val Loss: 0.2698 | Val Acc: 0.9026\n",
            "Epoch 9/10 | Train Loss: 0.2714 | Val Loss: 0.2211 | Val Acc: 0.9265\n",
            "Epoch 10/10 | Train Loss: 0.2951 | Val Loss: 0.2195 | Val Acc: 0.9335\n",
            "Test Loss: 0.2194 | Test Acc: 0.9335\n",
            "Epoch 1/10 | Train Loss: 0.3590 | Val Loss: 0.3529 | Val Acc: 0.8909\n",
            "Epoch 2/10 | Train Loss: 0.3154 | Val Loss: 0.2572 | Val Acc: 0.9111\n",
            "Epoch 3/10 | Train Loss: 0.3026 | Val Loss: 0.2997 | Val Acc: 0.9045\n",
            "Epoch 4/10 | Train Loss: 0.3094 | Val Loss: 0.2862 | Val Acc: 0.9203\n",
            "Epoch 5/10 | Train Loss: 0.3160 | Val Loss: 0.2458 | Val Acc: 0.9225\n",
            "Epoch 6/10 | Train Loss: 0.3835 | Val Loss: 0.2440 | Val Acc: 0.9177\n",
            "Epoch 7/10 | Train Loss: 0.3141 | Val Loss: 0.2510 | Val Acc: 0.9148\n",
            "Epoch 8/10 | Train Loss: 0.3231 | Val Loss: 0.2454 | Val Acc: 0.9192\n",
            "Epoch 9/10 | Train Loss: 0.3175 | Val Loss: 0.2509 | Val Acc: 0.9240\n",
            "Epoch 10/10 | Train Loss: 0.3777 | Val Loss: 0.5103 | Val Acc: 0.8075\n",
            "Test Loss: 0.5101 | Test Acc: 0.8075\n",
            "Epoch 1/10 | Train Loss: 0.3375 | Val Loss: 0.2863 | Val Acc: 0.8957\n",
            "Epoch 2/10 | Train Loss: 0.2709 | Val Loss: 0.2417 | Val Acc: 0.9155\n",
            "Epoch 3/10 | Train Loss: 0.2563 | Val Loss: 0.2216 | Val Acc: 0.9298\n",
            "Epoch 4/10 | Train Loss: 0.2575 | Val Loss: 0.2034 | Val Acc: 0.9280\n",
            "Epoch 5/10 | Train Loss: 0.2412 | Val Loss: 0.2301 | Val Acc: 0.9229\n",
            "Epoch 6/10 | Train Loss: 0.2518 | Val Loss: 0.2235 | Val Acc: 0.9203\n",
            "Epoch 7/10 | Train Loss: 0.2455 | Val Loss: 0.2257 | Val Acc: 0.9236\n",
            "Epoch 8/10 | Train Loss: 0.2416 | Val Loss: 0.2201 | Val Acc: 0.9280\n",
            "Epoch 9/10 | Train Loss: 0.2380 | Val Loss: 0.2048 | Val Acc: 0.9291\n",
            "Epoch 10/10 | Train Loss: 0.2476 | Val Loss: 0.1945 | Val Acc: 0.9357\n",
            "Test Loss: 0.1945 | Test Acc: 0.9357\n",
            "Epoch 1/10 | Train Loss: 0.3545 | Val Loss: 0.3412 | Val Acc: 0.8733\n",
            "Epoch 2/10 | Train Loss: 0.2949 | Val Loss: 0.2672 | Val Acc: 0.9078\n",
            "Epoch 3/10 | Train Loss: 0.2756 | Val Loss: 0.2913 | Val Acc: 0.9093\n",
            "Epoch 4/10 | Train Loss: 0.2798 | Val Loss: 0.2464 | Val Acc: 0.9181\n",
            "Epoch 5/10 | Train Loss: 0.2687 | Val Loss: 0.2234 | Val Acc: 0.9221\n",
            "Epoch 6/10 | Train Loss: 0.3060 | Val Loss: 0.3093 | Val Acc: 0.8997\n",
            "Epoch 7/10 | Train Loss: 0.2826 | Val Loss: 0.2186 | Val Acc: 0.9291\n",
            "Epoch 8/10 | Train Loss: 0.6389 | Val Loss: 0.7508 | Val Acc: 0.7256\n",
            "Epoch 9/10 | Train Loss: 0.6116 | Val Loss: 0.4367 | Val Acc: 0.8453\n",
            "Epoch 10/10 | Train Loss: 0.4290 | Val Loss: 0.2829 | Val Acc: 0.9129\n",
            "Test Loss: 0.2828 | Test Acc: 0.9129\n",
            "Epoch 1/10 | Train Loss: 0.3745 | Val Loss: 0.2478 | Val Acc: 0.9129\n",
            "Epoch 2/10 | Train Loss: 0.3065 | Val Loss: 0.2923 | Val Acc: 0.9030\n",
            "Epoch 3/10 | Train Loss: 0.2989 | Val Loss: 0.2367 | Val Acc: 0.9210\n",
            "Epoch 4/10 | Train Loss: 0.2957 | Val Loss: 0.2551 | Val Acc: 0.9104\n",
            "Epoch 5/10 | Train Loss: 0.2985 | Val Loss: 0.2983 | Val Acc: 0.9085\n",
            "Epoch 6/10 | Train Loss: 0.3532 | Val Loss: 0.2822 | Val Acc: 0.9074\n",
            "Epoch 7/10 | Train Loss: 0.3032 | Val Loss: 0.2497 | Val Acc: 0.9173\n",
            "Epoch 8/10 | Train Loss: 0.2755 | Val Loss: 0.2900 | Val Acc: 0.9122\n",
            "Epoch 9/10 | Train Loss: 0.3039 | Val Loss: 0.2244 | Val Acc: 0.9181\n",
            "Epoch 10/10 | Train Loss: 0.2959 | Val Loss: 0.2727 | Val Acc: 0.9093\n",
            "Test Loss: 0.2726 | Test Acc: 0.9093\n",
            "Epoch 1/10 | Train Loss: 0.3465 | Val Loss: 0.2500 | Val Acc: 0.9074\n",
            "Epoch 2/10 | Train Loss: 0.2764 | Val Loss: 0.2768 | Val Acc: 0.9067\n",
            "Epoch 3/10 | Train Loss: 0.2629 | Val Loss: 0.1893 | Val Acc: 0.9339\n",
            "Epoch 4/10 | Train Loss: 0.2515 | Val Loss: 0.2913 | Val Acc: 0.8894\n",
            "Epoch 5/10 | Train Loss: 0.2338 | Val Loss: 0.2401 | Val Acc: 0.9177\n",
            "Epoch 6/10 | Train Loss: 0.2476 | Val Loss: 0.2425 | Val Acc: 0.9140\n",
            "Epoch 7/10 | Train Loss: 0.2362 | Val Loss: 0.2288 | Val Acc: 0.9217\n",
            "Epoch 8/10 | Train Loss: 0.2371 | Val Loss: 0.2219 | Val Acc: 0.9276\n",
            "Epoch 9/10 | Train Loss: 0.2427 | Val Loss: 0.2323 | Val Acc: 0.9151\n",
            "Epoch 10/10 | Train Loss: 0.2523 | Val Loss: 0.2134 | Val Acc: 0.9273\n",
            "Test Loss: 0.2133 | Test Acc: 0.9273\n",
            "Epoch 1/10 | Train Loss: 0.3522 | Val Loss: 0.2789 | Val Acc: 0.8993\n",
            "Epoch 2/10 | Train Loss: 0.2900 | Val Loss: 0.2309 | Val Acc: 0.9173\n",
            "Epoch 3/10 | Train Loss: 0.2812 | Val Loss: 0.2397 | Val Acc: 0.9129\n",
            "Epoch 4/10 | Train Loss: 0.2587 | Val Loss: 0.2213 | Val Acc: 0.9210\n",
            "Epoch 5/10 | Train Loss: 0.2637 | Val Loss: 0.2178 | Val Acc: 0.9258\n",
            "Epoch 6/10 | Train Loss: 0.2592 | Val Loss: 0.2495 | Val Acc: 0.9177\n",
            "Epoch 7/10 | Train Loss: 0.2553 | Val Loss: 0.2136 | Val Acc: 0.9295\n",
            "Epoch 8/10 | Train Loss: 0.2670 | Val Loss: 0.2366 | Val Acc: 0.9170\n",
            "Epoch 9/10 | Train Loss: 0.2828 | Val Loss: 0.2653 | Val Acc: 0.9056\n",
            "Epoch 10/10 | Train Loss: 0.2672 | Val Loss: 0.2298 | Val Acc: 0.9225\n",
            "Test Loss: 0.2297 | Test Acc: 0.9225\n",
            "Epoch 1/10 | Train Loss: 0.3687 | Val Loss: 0.3082 | Val Acc: 0.8979\n",
            "Epoch 2/10 | Train Loss: 0.3029 | Val Loss: 0.2619 | Val Acc: 0.9144\n",
            "Epoch 3/10 | Train Loss: 0.2915 | Val Loss: 0.2362 | Val Acc: 0.9133\n",
            "Epoch 4/10 | Train Loss: 0.2810 | Val Loss: 0.4013 | Val Acc: 0.8630\n",
            "Epoch 5/10 | Train Loss: 0.3010 | Val Loss: 0.2329 | Val Acc: 0.9236\n",
            "Epoch 6/10 | Train Loss: 0.2794 | Val Loss: 0.2336 | Val Acc: 0.9221\n",
            "Epoch 7/10 | Train Loss: 0.2857 | Val Loss: 0.4784 | Val Acc: 0.8435\n",
            "Epoch 8/10 | Train Loss: 0.3025 | Val Loss: 0.3100 | Val Acc: 0.8964\n",
            "Epoch 9/10 | Train Loss: 0.2781 | Val Loss: 0.2817 | Val Acc: 0.9137\n",
            "Epoch 10/10 | Train Loss: 0.2868 | Val Loss: 0.2495 | Val Acc: 0.9096\n",
            "Test Loss: 0.2494 | Test Acc: 0.9096\n",
            "Epoch 1/10 | Train Loss: 0.3666 | Val Loss: 0.3264 | Val Acc: 0.8861\n",
            "Epoch 2/10 | Train Loss: 0.2836 | Val Loss: 0.2651 | Val Acc: 0.9041\n",
            "Epoch 3/10 | Train Loss: 0.2855 | Val Loss: 0.2726 | Val Acc: 0.9115\n",
            "Epoch 4/10 | Train Loss: 0.2742 | Val Loss: 0.2579 | Val Acc: 0.9144\n",
            "Epoch 5/10 | Train Loss: 0.2784 | Val Loss: 0.2272 | Val Acc: 0.9236\n",
            "Epoch 6/10 | Train Loss: 0.3259 | Val Loss: 0.4852 | Val Acc: 0.8354\n",
            "Epoch 7/10 | Train Loss: 1.6445 | Val Loss: 1.7816 | Val Acc: 0.2895\n",
            "Epoch 8/10 | Train Loss: 1.7684 | Val Loss: 1.6486 | Val Acc: 0.3553\n",
            "Epoch 9/10 | Train Loss: 1.6018 | Val Loss: 1.5453 | Val Acc: 0.3608\n",
            "Epoch 10/10 | Train Loss: 1.6109 | Val Loss: 1.5722 | Val Acc: 0.3200\n",
            "Test Loss: 1.5716 | Test Acc: 0.3200\n",
            "Epoch 1/10 | Train Loss: 0.3809 | Val Loss: 0.3072 | Val Acc: 0.8924\n",
            "Epoch 2/10 | Train Loss: 0.3096 | Val Loss: 0.2681 | Val Acc: 0.9019\n",
            "Epoch 3/10 | Train Loss: 0.2913 | Val Loss: 0.2515 | Val Acc: 0.9162\n",
            "Epoch 4/10 | Train Loss: 0.2851 | Val Loss: 0.3273 | Val Acc: 0.8857\n",
            "Epoch 5/10 | Train Loss: 0.2972 | Val Loss: 0.2311 | Val Acc: 0.9199\n",
            "Epoch 6/10 | Train Loss: 0.4659 | Val Loss: 1.8364 | Val Acc: 0.1539\n",
            "Epoch 7/10 | Train Loss: 1.7064 | Val Loss: 1.5130 | Val Acc: 0.2645\n",
            "Epoch 8/10 | Train Loss: 1.5813 | Val Loss: 1.4983 | Val Acc: 0.3744\n",
            "Epoch 9/10 | Train Loss: 1.7201 | Val Loss: 1.8781 | Val Acc: 0.2597\n",
            "Epoch 10/10 | Train Loss: 1.8261 | Val Loss: 1.8367 | Val Acc: 0.2605\n",
            "Test Loss: 1.8360 | Test Acc: 0.2605\n",
            "Epoch 1/10 | Train Loss: 0.3975 | Val Loss: 0.3685 | Val Acc: 0.8788\n",
            "Epoch 2/10 | Train Loss: 0.3496 | Val Loss: 0.3503 | Val Acc: 0.8641\n",
            "Epoch 3/10 | Train Loss: 0.3461 | Val Loss: 0.2553 | Val Acc: 0.9162\n",
            "Epoch 4/10 | Train Loss: 0.3616 | Val Loss: 0.3534 | Val Acc: 0.8891\n",
            "Epoch 5/10 | Train Loss: 0.7323 | Val Loss: 1.2859 | Val Acc: 0.4717\n",
            "Epoch 6/10 | Train Loss: 1.7015 | Val Loss: 1.7796 | Val Acc: 0.3303\n",
            "Epoch 7/10 | Train Loss: 1.8333 | Val Loss: 1.8478 | Val Acc: 0.2605\n",
            "Epoch 8/10 | Train Loss: 1.8452 | Val Loss: 1.8578 | Val Acc: 0.2605\n",
            "Epoch 9/10 | Train Loss: 1.8464 | Val Loss: 1.8392 | Val Acc: 0.2605\n",
            "Epoch 10/10 | Train Loss: 1.8413 | Val Loss: 1.8466 | Val Acc: 0.2605\n",
            "Test Loss: 1.8459 | Test Acc: 0.2605\n",
            "Epoch 1/10 | Train Loss: 0.3676 | Val Loss: 0.2778 | Val Acc: 0.9060\n",
            "Epoch 2/10 | Train Loss: 0.2794 | Val Loss: 0.2691 | Val Acc: 0.9085\n",
            "Epoch 3/10 | Train Loss: 0.2771 | Val Loss: 0.2270 | Val Acc: 0.9199\n",
            "Epoch 4/10 | Train Loss: 0.2671 | Val Loss: 0.2825 | Val Acc: 0.9015\n",
            "Epoch 5/10 | Train Loss: 0.2924 | Val Loss: 0.2834 | Val Acc: 0.9060\n",
            "Epoch 6/10 | Train Loss: 0.2967 | Val Loss: 0.3199 | Val Acc: 0.8758\n",
            "Epoch 7/10 | Train Loss: 1.0609 | Val Loss: 1.3782 | Val Acc: 0.2439\n",
            "Epoch 8/10 | Train Loss: 1.3751 | Val Loss: 1.3438 | Val Acc: 0.3924\n",
            "Epoch 9/10 | Train Loss: 1.3840 | Val Loss: 1.3834 | Val Acc: 0.3784\n",
            "Epoch 10/10 | Train Loss: 1.4134 | Val Loss: 1.3224 | Val Acc: 0.3854\n",
            "Test Loss: 1.3219 | Test Acc: 0.3854\n",
            "Epoch 1/10 | Train Loss: 0.3719 | Val Loss: 0.2483 | Val Acc: 0.9170\n",
            "Epoch 2/10 | Train Loss: 0.3071 | Val Loss: 0.2497 | Val Acc: 0.9195\n",
            "Epoch 3/10 | Train Loss: 0.2840 | Val Loss: 0.2289 | Val Acc: 0.9240\n",
            "Epoch 4/10 | Train Loss: 0.2856 | Val Loss: 0.2030 | Val Acc: 0.9287\n",
            "Epoch 5/10 | Train Loss: 0.2881 | Val Loss: 0.2516 | Val Acc: 0.9254\n",
            "Epoch 6/10 | Train Loss: 0.2874 | Val Loss: 0.2148 | Val Acc: 0.9269\n",
            "Epoch 7/10 | Train Loss: 0.2920 | Val Loss: 0.3107 | Val Acc: 0.8942\n",
            "Epoch 8/10 | Train Loss: 0.3063 | Val Loss: 0.2204 | Val Acc: 0.9276\n",
            "Epoch 9/10 | Train Loss: 0.2769 | Val Loss: 0.2447 | Val Acc: 0.9159\n",
            "Epoch 10/10 | Train Loss: 0.2822 | Val Loss: 0.3135 | Val Acc: 0.8993\n",
            "Test Loss: 0.3134 | Test Acc: 0.8993\n",
            "Epoch 1/10 | Train Loss: 0.4056 | Val Loss: 0.2489 | Val Acc: 0.9129\n",
            "Epoch 2/10 | Train Loss: 0.3301 | Val Loss: 0.3961 | Val Acc: 0.8681\n",
            "Epoch 3/10 | Train Loss: 0.3319 | Val Loss: 0.3488 | Val Acc: 0.8942\n",
            "Epoch 4/10 | Train Loss: 0.3181 | Val Loss: 0.2814 | Val Acc: 0.9155\n",
            "Epoch 5/10 | Train Loss: 0.3208 | Val Loss: 0.3312 | Val Acc: 0.9034\n",
            "Epoch 6/10 | Train Loss: 0.3520 | Val Loss: 0.3113 | Val Acc: 0.9015\n",
            "Epoch 7/10 | Train Loss: 0.3395 | Val Loss: 0.3108 | Val Acc: 0.9063\n",
            "Epoch 8/10 | Train Loss: 0.3555 | Val Loss: 0.3171 | Val Acc: 0.8993\n",
            "Epoch 9/10 | Train Loss: 0.4653 | Val Loss: 0.4008 | Val Acc: 0.8791\n",
            "Epoch 10/10 | Train Loss: 0.7260 | Val Loss: 0.7560 | Val Acc: 0.7575\n",
            "Test Loss: 0.7557 | Test Acc: 0.7575\n",
            "Epoch 1/10 | Train Loss: 0.3588 | Val Loss: 0.2731 | Val Acc: 0.9034\n",
            "Epoch 2/10 | Train Loss: 0.2706 | Val Loss: 0.2044 | Val Acc: 0.9306\n",
            "Epoch 3/10 | Train Loss: 0.2890 | Val Loss: 0.2200 | Val Acc: 0.9206\n",
            "Epoch 4/10 | Train Loss: 0.2682 | Val Loss: 0.2182 | Val Acc: 0.9240\n",
            "Epoch 5/10 | Train Loss: 0.2590 | Val Loss: 0.2558 | Val Acc: 0.9012\n",
            "Epoch 6/10 | Train Loss: 0.2529 | Val Loss: 0.2170 | Val Acc: 0.9269\n",
            "Epoch 7/10 | Train Loss: 0.2360 | Val Loss: 0.2026 | Val Acc: 0.9232\n",
            "Epoch 8/10 | Train Loss: 0.2409 | Val Loss: 0.2459 | Val Acc: 0.9210\n",
            "Epoch 9/10 | Train Loss: 0.2694 | Val Loss: 0.3363 | Val Acc: 0.8857\n",
            "Epoch 10/10 | Train Loss: 0.2864 | Val Loss: 0.4004 | Val Acc: 0.8453\n",
            "Test Loss: 0.4003 | Test Acc: 0.8453\n",
            "Epoch 1/10 | Train Loss: 0.3919 | Val Loss: 0.3083 | Val Acc: 0.8968\n",
            "Epoch 2/10 | Train Loss: 0.3054 | Val Loss: 0.2588 | Val Acc: 0.9104\n",
            "Epoch 3/10 | Train Loss: 0.2993 | Val Loss: 0.2076 | Val Acc: 0.9302\n",
            "Epoch 4/10 | Train Loss: 0.2831 | Val Loss: 0.2569 | Val Acc: 0.9129\n",
            "Epoch 5/10 | Train Loss: 0.2706 | Val Loss: 0.3075 | Val Acc: 0.8909\n",
            "Epoch 6/10 | Train Loss: 0.2613 | Val Loss: 0.2776 | Val Acc: 0.9074\n",
            "Epoch 7/10 | Train Loss: 0.2719 | Val Loss: 0.3259 | Val Acc: 0.9019\n",
            "Epoch 8/10 | Train Loss: 0.2920 | Val Loss: 0.2177 | Val Acc: 0.9243\n",
            "Epoch 9/10 | Train Loss: 0.2964 | Val Loss: 0.3102 | Val Acc: 0.9001\n",
            "Epoch 10/10 | Train Loss: 0.4400 | Val Loss: 0.3225 | Val Acc: 0.8843\n",
            "Test Loss: 0.3224 | Test Acc: 0.8843\n",
            "Epoch 1/10 | Train Loss: 0.3857 | Val Loss: 0.3073 | Val Acc: 0.8990\n",
            "Epoch 2/10 | Train Loss: 0.3492 | Val Loss: 0.3202 | Val Acc: 0.8865\n",
            "Epoch 3/10 | Train Loss: 0.3278 | Val Loss: 0.2467 | Val Acc: 0.9214\n",
            "Epoch 4/10 | Train Loss: 0.3139 | Val Loss: 0.3388 | Val Acc: 0.8868\n",
            "Epoch 5/10 | Train Loss: 0.3511 | Val Loss: 0.2801 | Val Acc: 0.9074\n",
            "Epoch 6/10 | Train Loss: 0.3291 | Val Loss: 0.2737 | Val Acc: 0.9122\n",
            "Epoch 7/10 | Train Loss: 0.3117 | Val Loss: 0.2350 | Val Acc: 0.9243\n",
            "Epoch 8/10 | Train Loss: 0.3149 | Val Loss: 0.2987 | Val Acc: 0.9144\n",
            "Epoch 9/10 | Train Loss: 0.4179 | Val Loss: 0.4604 | Val Acc: 0.8758\n",
            "Epoch 10/10 | Train Loss: 0.5227 | Val Loss: 0.3224 | Val Acc: 0.9015\n",
            "Test Loss: 0.3223 | Test Acc: 0.9015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJA0XU0anOwJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}